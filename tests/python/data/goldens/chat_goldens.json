[
    {
        "input": "Why do scientific biographies typically exclude the errors made by illustrious researchers?",
        "actual_output": null,
        "expected_output": "Scientific biographies often exclude the errors made by illustrious researchers because these narratives tend to highlight their successes, creating an impression of unerring judgment. Mistakes are edited out, leading us to underestimate the risks these scientists took, and overemphasize the correctness of their successful theories, which have become conventional wisdom. Additionally, focusing on successes rather than failures simplifies the storytelling and aligns with the public perception of brilliant scientists having a clear, uninterrupted path to discovery.",
        "context": [
            "The Risk of Discovery\n\nJanuary 2017Because biographies of famous scientists tend to \nedit out their mistakes, we underestimate the \ndegree of risk they were willing to take.\nAnd because anything a famous scientist did that\nwasn't a mistake has probably now become the\nconventional wisdom, those choices don't\nseem risky either.Biographies of Newton, for example, understandably focus\nmore on physics than alchemy or theology.\nThe impression we get is that his unerring judgment\nled him straight to truths no one else had noticed.\nHow to explain all the time he spent on alchemy\nand theology?  Well, smart people are often kind of\ncrazy.But maybe there is a simpler explanation. Maybe\nthe smartness and the craziness were not as separate\nas we think. Physics seems to us a promising thing\nto work on, and alchemy and theology obvious wastes\nof time. But that's because we know how things\nturned out. In Newton's day the three problems \nseemed roughly equally promising. No one knew yet\nwhat the payoff would be for inventing what we\nnow call physics; if they had, more people would \nhave been working on it. And alchemy and theology\nwere still then in the category Marc Andreessen would \ndescribe as \"huge, if true.\"Newton made three bets. One of them worked. But \nthey were all risky.Japanese Translation"
        ],
        "source_file": null
    },
    {
        "input": "Assess the relative risk of Newton's endeavors in physics, alchemy, and theology.",
        "actual_output": null,
        "expected_output": "In Newton's time, the relative risk of his endeavors in physics, alchemy, and theology was difficult to gauge. Today, physics is seen as a significant scientific breakthrough, but at the time, it was just as speculative as alchemy and theology. All three fields appeared equally promising because their potential impacts were not yet understood. Newton took a risk by investing time in each of these areas, not knowing which would yield fruitful results. In hindsight, physics turned out to be the most rewarding, but the uncertainty of the outcomes at the time made each pursuit equally risky.",
        "context": [
            "The Risk of Discovery\n\nJanuary 2017Because biographies of famous scientists tend to \nedit out their mistakes, we underestimate the \ndegree of risk they were willing to take.\nAnd because anything a famous scientist did that\nwasn't a mistake has probably now become the\nconventional wisdom, those choices don't\nseem risky either.Biographies of Newton, for example, understandably focus\nmore on physics than alchemy or theology.\nThe impression we get is that his unerring judgment\nled him straight to truths no one else had noticed.\nHow to explain all the time he spent on alchemy\nand theology?  Well, smart people are often kind of\ncrazy.But maybe there is a simpler explanation. Maybe\nthe smartness and the craziness were not as separate\nas we think. Physics seems to us a promising thing\nto work on, and alchemy and theology obvious wastes\nof time. But that's because we know how things\nturned out. In Newton's day the three problems \nseemed roughly equally promising. No one knew yet\nwhat the payoff would be for inventing what we\nnow call physics; if they had, more people would \nhave been working on it. And alchemy and theology\nwere still then in the category Marc Andreessen would \ndescribe as \"huge, if true.\"Newton made three bets. One of them worked. But \nthey were all risky.Japanese Translation"
        ],
        "source_file": null
    },
    {
        "input": "Analyze why individuals who possess power yet lack charisma are often criticized, especially in leadership roles like CEO, and how recognition of this dynamic as a natural human tendency might imply suitability for their position.",
        "actual_output": null,
        "expected_output": "Individuals who hold power but lack charisma are often criticized because their inability to connect personally makes them easy targets for criticism, which their charisma-deficient demeanor cannot effectively mitigate. This dynamic is especially evident in leadership roles like CEOs, where being a builder-type, focusing on practical and strategic excellence, can overshadow the lack of interpersonal charm. Recognizing this pattern as a natural human tendency suggests that enduring criticism is not necessarily a flaw but might actually indicate suitability for the role. People like Hillary Clinton or builder-type CEOs, despite facing heavy criticism, may actually be well-suited for their positions due to their competence and ability to focus on goals rather than winning popularity contests.",
        "context": [
            "Charisma / Power\n\nJanuary 2017People who are powerful but uncharismatic will tend to be disliked.\nTheir power makes them a target for criticism that they don't have\nthe charisma to disarm. That was Hillary Clinton's problem. It also\ntends to be a problem for any CEO who is more of a builder than a\nschmoozer. And yet the builder-type CEO is (like Hillary) probably\nthe best person for the job.I don't think there is any solution to this problem. It's human\nnature. The best we can do is to recognize that it's happening, and\nto understand that being a magnet for criticism is sometimes a sign\nnot that someone is the wrong person for a job, but that they're\nthe right one."
        ],
        "source_file": null
    },
    {
        "input": "Imagine a scenario where a non-charismatic leader overcomes criticism; how does their role suitability influence perceptions?",
        "actual_output": null,
        "expected_output": "In a scenario where a non-charismatic leader overcomes criticism, their role suitability can positively influence perceptions by highlighting their competence and effectiveness. While they may lack the charisma to disarm criticism, their ability to deliver results and build successfully can gradually shift opinions. People might start recognizing that being a target for criticism isn't necessarily a reflection of incompetence but an indication of their significant impact and leadership suitability. Over time, this awareness can lead to a broader appreciation of their strengths as the right person for the job.",
        "context": [
            "Charisma / Power\n\nJanuary 2017People who are powerful but uncharismatic will tend to be disliked.\nTheir power makes them a target for criticism that they don't have\nthe charisma to disarm. That was Hillary Clinton's problem. It also\ntends to be a problem for any CEO who is more of a builder than a\nschmoozer. And yet the builder-type CEO is (like Hillary) probably\nthe best person for the job.I don't think there is any solution to this problem. It's human\nnature. The best we can do is to recognize that it's happening, and\nto understand that being a magnet for criticism is sometimes a sign\nnot that someone is the wrong person for a job, but that they're\nthe right one."
        ],
        "source_file": null
    },
    {
        "input": "How do AI's emergence and writing's cognitive demands complicate the skill of writing today?",
        "actual_output": null,
        "expected_output": "AI's emergence reduces the pressure to write, as it can perform writing tasks for people in both educational and professional settings. While this may seem like an advantage, it complicates the skill of writing by potentially diminishing the necessity for individuals to engage in the cognitive demands associated with it. Writing is closely tied to clear thinking, and as AI takes over writing tasks, fewer people may develop these critical thinking skills. This creates a divide between those who can write—and by extension, think—and those who do not, resulting in a world of \"writes\" and \"write-nots,\" or more broadly, \"thinks\" and \"think-nots.\"",
        "context": [
            "Writes and Write-Nots\n\nOctober 2024I'm usually reluctant to make predictions about technology, but I\nfeel fairly confident about this one: in a couple decades there\nwon't be many people who can write.One of the strangest things you learn if you're a writer is how\nmany people have trouble writing. Doctors know how many people have\na mole they're worried about; people who are good at setting up\ncomputers know how many people aren't; writers know how many people\nneed help writing.The reason so many people have trouble writing is that it's\nfundamentally difficult. To write well you have to think clearly,\nand thinking clearly is hard.And yet writing pervades many jobs, and the more prestigious the\njob, the more writing it tends to require.These two powerful opposing forces, the pervasive expectation of\nwriting and the irreducible difficulty of doing it, create enormous\npressure. This is why eminent professors often turn out to have\nresorted to plagiarism. The most striking thing to me about these\ncases is the pettiness of the thefts. The stuff they steal is usually\nthe most mundane boilerplate — the sort of thing that anyone who\nwas even halfway decent at writing could turn out with no effort\nat all. Which means they're not even halfway decent at writing.Till recently there was no convenient escape valve for the pressure\ncreated by these opposing forces. You could pay someone to write\nfor you, like JFK, or plagiarize, like MLK, but if you couldn't buy\nor steal words, you had to write them yourself. And as a result\nnearly everyone who was expected to write had to learn how.Not anymore. AI has blown this world open. Almost all pressure to\nwrite has dissipated. You can have AI do it for you, both in school\nand at work.The result will be a world divided into writes and write-nots.\nThere will still be some people who can write. Some of us like it.\nBut the middle ground between those who are good at writing and\nthose who can't write at all will disappear. Instead of good writers,\nok writers, and people who can't write, there will just be good\nwriters and people who can't write.Is that so bad? Isn't it common for skills to disappear when\ntechnology makes them obsolete? There aren't many blacksmiths left,\nand it doesn't seem to be a problem.Yes, it's bad. The reason is something I mentioned earlier: writing\nis thinking. In fact there's a kind of thinking that can only be\ndone by writing. You can't make this point better than Leslie Lamport\ndid:\n\n  If you're thinking without writing, you only think you're thinking.\n\nSo a world divided into writes and write-nots is more dangerous\nthan it sounds. It will be a world of thinks and think-nots. I know\nwhich half I want to be in, and I bet you do too.This situation is not unprecedented. In preindustrial times most\npeople's jobs made them strong. Now if you want to be strong, you\nwork out. So there are still strong people, but only those who\nchoose to be.It will be the same with writing. There will still be smart people,\nbut only those who choose to be.Thanks to Jessica Livingston, Ben Miller, \nand Robert Morris for reading drafts of this."
        ],
        "source_file": null
    },
    {
        "input": "Contrast the implications of a future societal divide between \"writes\" and \"write-nots\" on literacy versus digital communication skills.",
        "actual_output": null,
        "expected_output": "In a future societal divide between \"writes\" and \"write-nots,\" literacy may suffer as fewer people engage in the active process of writing, which is closely tied to thinking and cognitive development. This could lead to a diminished capacity for deep, critical thought among \"write-nots,\" who rely heavily on AI for their writing needs. On the other hand, digital communication skills could flourish as technology becomes the primary medium for communication. People may become adept at interacting with AI and utilizing digital tools, but this shift might result in a superficial understanding and limited expression, lacking the depth that comes from traditional literacy and the art of writing. Overall, while digital communication skills may advance, the critical thinking and analytical aspects nurtured through writing could be at risk.",
        "context": [
            "Writes and Write-Nots\n\nOctober 2024I'm usually reluctant to make predictions about technology, but I\nfeel fairly confident about this one: in a couple decades there\nwon't be many people who can write.One of the strangest things you learn if you're a writer is how\nmany people have trouble writing. Doctors know how many people have\na mole they're worried about; people who are good at setting up\ncomputers know how many people aren't; writers know how many people\nneed help writing.The reason so many people have trouble writing is that it's\nfundamentally difficult. To write well you have to think clearly,\nand thinking clearly is hard.And yet writing pervades many jobs, and the more prestigious the\njob, the more writing it tends to require.These two powerful opposing forces, the pervasive expectation of\nwriting and the irreducible difficulty of doing it, create enormous\npressure. This is why eminent professors often turn out to have\nresorted to plagiarism. The most striking thing to me about these\ncases is the pettiness of the thefts. The stuff they steal is usually\nthe most mundane boilerplate — the sort of thing that anyone who\nwas even halfway decent at writing could turn out with no effort\nat all. Which means they're not even halfway decent at writing.Till recently there was no convenient escape valve for the pressure\ncreated by these opposing forces. You could pay someone to write\nfor you, like JFK, or plagiarize, like MLK, but if you couldn't buy\nor steal words, you had to write them yourself. And as a result\nnearly everyone who was expected to write had to learn how.Not anymore. AI has blown this world open. Almost all pressure to\nwrite has dissipated. You can have AI do it for you, both in school\nand at work.The result will be a world divided into writes and write-nots.\nThere will still be some people who can write. Some of us like it.\nBut the middle ground between those who are good at writing and\nthose who can't write at all will disappear. Instead of good writers,\nok writers, and people who can't write, there will just be good\nwriters and people who can't write.Is that so bad? Isn't it common for skills to disappear when\ntechnology makes them obsolete? There aren't many blacksmiths left,\nand it doesn't seem to be a problem.Yes, it's bad. The reason is something I mentioned earlier: writing\nis thinking. In fact there's a kind of thinking that can only be\ndone by writing. You can't make this point better than Leslie Lamport\ndid:\n\n  If you're thinking without writing, you only think you're thinking.\n\nSo a world divided into writes and write-nots is more dangerous\nthan it sounds. It will be a world of thinks and think-nots. I know\nwhich half I want to be in, and I bet you do too.This situation is not unprecedented. In preindustrial times most\npeople's jobs made them strong. Now if you want to be strong, you\nwork out. So there are still strong people, but only those who\nchoose to be.It will be the same with writing. There will still be smart people,\nbut only those who choose to be.Thanks to Jessica Livingston, Ben Miller, \nand Robert Morris for reading drafts of this."
        ],
        "source_file": null
    },
    {
        "input": "How do readers' traits and info importance influence knowledge of essay topics?",
        "actual_output": null,
        "expected_output": "Readers' traits and the importance of information influence their knowledge of essay topics by determining whether they already know about the topics and how they will engage with new information. Readers may not know something because it is not important, they are inexperienced, or they are obtuse. The most impactful essays change readers' thinking by telling them things they don't already know, especially targeting younger readers who have more room for changing their thinking. The importance of the topic also affects how much their thinking can be changed. Therefore, essays about important subjects are most effective with younger, smart readers.",
        "context": [
            "The Shape of the Essay Field\n\nJune 2025An essay has to tell people something they don't already know. But\nthere are three different reasons people might not know something,\nand they yield three very different kinds of essays.One reason people won't know something is if it's not important to\nknow. That doesn't mean it will make a bad essay. For example, you\nmight write a good essay about a particular model of car. Readers\nwould learn something from it. It would add to their picture of the\nworld. For a handful of readers it might even spur some kind of\nepiphany. But unless this is a very unusual car it's not critical\nfor everyone to know about it. \n[1]If something isn't important to know, there's no answer to the\nquestion of why people don't know it. Not knowing random facts is\nthe default. But if you're going to write about things that are\nimportant to know, you have to ask why your readers don't already\nknow them. Is it because they're smart but inexperienced, or because\nthey're obtuse?So the three reasons readers might not already know what you tell\nthem are (a) that it's not important, (b) that they're obtuse, \nor (c) that they're inexperienced.The reason I did this breakdown was to get at the following fact,\nwhich might have seemed controversial if I'd led with it, but should\nbe obvious now. If you're writing for smart people about important\nthings, you're writing for the young.Or more precisely, that's where you'll have the most effect. Whatever\nyou say should also be at least somewhat novel to you, however old\nyou are. It's not an essay otherwise, because an essay is something\nyou write to figure something out. But whatever you figure out will\npresumably be more of a surprise to younger readers than it is to\nyou.There's a continuum of surprise. At one extreme, something you read\ncan change your whole way of thinking. The Selfish Gene did this\nto me. It was like suddenly seeing the other interpretation of an\nambiguous image: you can treat genes rather than organisms as the\nprotagonists, and evolution becomes easier to understand when you\ndo. At the other extreme, writing merely puts into words something\nreaders were already thinking — or thought they were.The impact of an essay is how much it changes readers' thinking\nmultiplied by the importance of the topic. But it's hard to do well\nat both. It's hard to have big new ideas about important topics.\nSo in practice there's a tradeoff: you can change readers' thinking\na lot about moderately important things, or change it a little about\nvery important ones. But with younger readers the tradeoff shifts.\nThere's more room to change their thinking, so there's a bigger\npayoff for writing about important things.The tradeoff isn't a conscious one, at least not for me. It's more\nlike a kind of gravitational field that writers work in. But every\nessayist works in it, whether they realize it or not.This seems obvious once you state it, but it took me a long time\nto understand. I knew I wanted to write for smart people about\nimportant topics. I noticed empirically that I seemed to be writing\nfor the young. But it took me years to understand that the latter\nwas an automatic consequence of the former. In fact I only really\nfigured it out as I was writing this essay.Now that I know it, should I change anything? I don't think so. In\nfact seeing the shape of the field that writers work in has reminded\nme that I'm not optimizing for returns in it. I'm not trying to\nsurprise readers of any particular age; I'm trying to surprise\nmyself.The way I usually decide what to write about is by following\ncuriosity. I notice something new and dig into it. It would probably\nbe a mistake to change that. But seeing the shape of the essay field\nhas set me thinking. What would surprise young readers? Which\nimportant things do people tend to learn late? Interesting question.\nI should think about that.\nNote[1]\nIt's hard to write a really good essay about an unimportant\ntopic, though, because a really good essayist will inevitably draw\nthe topic into deeper waters. E. B. White could write an essay about\nhow to boil potatoes that ended up being full of timeless wisdom.\nIn which case, of course, it wouldn't really be about how to boil\npotatoes; that would just have been the starting point.Thanks to Jessica Livingston and Michael \nNielsen for reading drafts of this."
        ],
        "source_file": null
    },
    {
        "input": "How does writing for young, smart readers impact their thinking as explored in 'The Shape of the Essay Field'?",
        "actual_output": null,
        "expected_output": "Writing for young, smart readers is particularly impactful because they have more room to change in their thinking. The essay suggests that writing about important things can lead to a bigger payoff with younger audiences, as they are more likely to experience significant shifts in perspective. Essentially, the same ideas are generally more novel and thus more surprising to younger readers, which enhances the effect of the essay.",
        "context": [
            "The Shape of the Essay Field\n\nJune 2025An essay has to tell people something they don't already know. But\nthere are three different reasons people might not know something,\nand they yield three very different kinds of essays.One reason people won't know something is if it's not important to\nknow. That doesn't mean it will make a bad essay. For example, you\nmight write a good essay about a particular model of car. Readers\nwould learn something from it. It would add to their picture of the\nworld. For a handful of readers it might even spur some kind of\nepiphany. But unless this is a very unusual car it's not critical\nfor everyone to know about it. \n[1]If something isn't important to know, there's no answer to the\nquestion of why people don't know it. Not knowing random facts is\nthe default. But if you're going to write about things that are\nimportant to know, you have to ask why your readers don't already\nknow them. Is it because they're smart but inexperienced, or because\nthey're obtuse?So the three reasons readers might not already know what you tell\nthem are (a) that it's not important, (b) that they're obtuse, \nor (c) that they're inexperienced.The reason I did this breakdown was to get at the following fact,\nwhich might have seemed controversial if I'd led with it, but should\nbe obvious now. If you're writing for smart people about important\nthings, you're writing for the young.Or more precisely, that's where you'll have the most effect. Whatever\nyou say should also be at least somewhat novel to you, however old\nyou are. It's not an essay otherwise, because an essay is something\nyou write to figure something out. But whatever you figure out will\npresumably be more of a surprise to younger readers than it is to\nyou.There's a continuum of surprise. At one extreme, something you read\ncan change your whole way of thinking. The Selfish Gene did this\nto me. It was like suddenly seeing the other interpretation of an\nambiguous image: you can treat genes rather than organisms as the\nprotagonists, and evolution becomes easier to understand when you\ndo. At the other extreme, writing merely puts into words something\nreaders were already thinking — or thought they were.The impact of an essay is how much it changes readers' thinking\nmultiplied by the importance of the topic. But it's hard to do well\nat both. It's hard to have big new ideas about important topics.\nSo in practice there's a tradeoff: you can change readers' thinking\na lot about moderately important things, or change it a little about\nvery important ones. But with younger readers the tradeoff shifts.\nThere's more room to change their thinking, so there's a bigger\npayoff for writing about important things.The tradeoff isn't a conscious one, at least not for me. It's more\nlike a kind of gravitational field that writers work in. But every\nessayist works in it, whether they realize it or not.This seems obvious once you state it, but it took me a long time\nto understand. I knew I wanted to write for smart people about\nimportant topics. I noticed empirically that I seemed to be writing\nfor the young. But it took me years to understand that the latter\nwas an automatic consequence of the former. In fact I only really\nfigured it out as I was writing this essay.Now that I know it, should I change anything? I don't think so. In\nfact seeing the shape of the field that writers work in has reminded\nme that I'm not optimizing for returns in it. I'm not trying to\nsurprise readers of any particular age; I'm trying to surprise\nmyself.The way I usually decide what to write about is by following\ncuriosity. I notice something new and dig into it. It would probably\nbe a mistake to change that. But seeing the shape of the essay field\nhas set me thinking. What would surprise young readers? Which\nimportant things do people tend to learn late? Interesting question.\nI should think about that.\nNote[1]\nIt's hard to write a really good essay about an unimportant\ntopic, though, because a really good essayist will inevitably draw\nthe topic into deeper waters. E. B. White could write an essay about\nhow to boil potatoes that ended up being full of timeless wisdom.\nIn which case, of course, it wouldn't really be about how to boil\npotatoes; that would just have been the starting point.Thanks to Jessica Livingston and Michael \nNielsen for reading drafts of this."
        ],
        "source_file": null
    },
    {
        "input": "Investigate the genesis of Reddit's affiliation with Y Combinator and subsequent evolution.",
        "actual_output": null,
        "expected_output": "Reddit's affiliation with Y Combinator began before the startup accelerator officially existed. Steve Huffman and Alexis Ohanian, the founders of Reddit, impressed Paul Graham, one of Y Combinator's founders, with their energy and intellect at a talk he gave at Harvard. Initially, their startup idea was to order fast food via cellphones, which was impractical at the time. Despite rejecting this initial idea, Graham was keen to fund Steve and Alexis due to their potential. He suggested they pivot to creating a site for sharing popular links, inspired by del.icio.us/popular, which led to the birth of Reddit.\n\nReddit launched quickly within three weeks of the first Y Combinator batch, involving a small group of users including the founders and their acquaintances. As Reddit grew, it attracted remarkably smart individuals, including Chris Slowe and Aaron Swartz. Despite fluctuating management quality over the years, Reddit's user-driven model proved highly resilient and grew steadily. In 2015, when Steve Huffman returned to the company, Reddit saw a resurgence in its growth and innovation, demonstrating the significance of its founders' continued involvement.",
        "context": [
            "The Reddits\n\nMarch 2024I met the Reddits before we even started Y Combinator. In fact they\nwere one of the reasons we started it.YC grew out of a talk I gave to the Harvard Computer Society (the\nundergrad computer club) about how to start a startup. Everyone\nelse in the audience was probably local, but Steve and Alexis came\nup on the train from the University of Virginia, where they were\nseniors. Since they'd come so far I agreed to meet them for coffee.\nThey told me about the startup idea we'd later fund them to drop:\na way to order fast food on your cellphone.This was before smartphones. They'd have had to make deals with\ncell carriers and fast food chains just to get it launched. So it\nwas not going to happen. It still doesn't exist, 19 years later.\nBut I was impressed with their brains and their energy. In fact I\nwas so impressed with them and some of the other people I met at\nthat talk that I decided to start something to fund them. A few\ndays later I told Steve and Alexis that we were starting Y Combinator,\nand encouraged them to apply.That first batch we didn't have any way to identify applicants, so\nwe made up nicknames for them. The Reddits were the \"Cell food\nmuffins.\" \"Muffin\" is a term of endearment Jessica uses for things\nlike small dogs and two year olds. So that gives you some idea what\nkind of impression Steve and Alexis made in those days. They had\nthe look of slightly ruffled surprise that baby birds have.Their idea was bad though. And since we thought then that we were\nfunding ideas rather than founders, we rejected them. But we felt\nbad about it. Jessica was sad that we'd rejected the muffins. And\nit seemed wrong to me to turn down the people we'd been inspired\nto start YC to fund.I don't think the startup sense of the word \"pivot\" had been invented\nyet, but we wanted to fund Steve and Alexis, so if their idea was\nbad, they'd have to work on something else. And I knew what else.\nIn those days there was a site called Delicious where you could\nsave links. It had a page called del.icio.us/popular that listed\nthe most-saved links, and people were using this page as a de facto\nReddit. I knew because a lot of the traffic to my site was coming\nfrom it. There needed to be something like del.icio.us/popular, but\ndesigned for sharing links instead of being a byproduct of saving\nthem.So I called Steve and Alexis and said that we liked them, just not\ntheir idea, so we'd fund them if they'd work on something else.\nThey were on the train home to Virginia at that point. They got off\nat the next station and got on the next train north, and by the end\nof the day were committed to working on what's now called Reddit.They would have liked to call it Snoo, as in \"What snoo?\" But\nsnoo.com was too expensive, so they settled for calling the mascot\nSnoo and picked a name for the site that wasn't registered. Early\non Reddit was just a provisional name, or so they told me at least,\nbut it's probably too late to change it now.As with all the really great startups, there's an uncannily close\nmatch between the company and the founders. Steve in particular.\nReddit has a certain personality — curious, skeptical, ready to\nbe amused — and that personality is Steve's.Steve will roll his eyes at this, but he's an intellectual; he's\ninterested in ideas for their own sake. That was how he came to be\nin that audience in Cambridge in the first place. He knew me because\nhe was interested in a programming language I've written about\ncalled Lisp, and Lisp is one of those languages few people learn\nexcept out of intellectual curiosity. Steve's kind of vacuum-cleaner\ncuriosity is exactly what you want when you're starting a site\nthat's a list of links to literally anything interesting.Steve was not a big fan of authority, so he also liked the idea of\na site without editors. In those days the top forum for programmers\nwas a site called Slashdot. It was a lot like Reddit, except the\nstories on the frontpage were chosen by human moderators. And though\nthey did a good job, that one small difference turned out to be a\nbig difference. Being driven by user submissions meant Reddit was\nfresher than Slashdot. News there was newer, and users will always\ngo where the newest news is.I pushed the Reddits to launch fast. A version one didn't need to\nbe more than a couple hundred lines of code. How could that take\nmore than a week or two to build? And they did launch comparatively\nfast, about three weeks into the first YC batch. The first users\nwere Steve, Alexis, me, and some of their YC batchmates and college\nfriends. It turns out you don't need that many users to collect a\ndecent list of interesting links, especially if you have multiple\naccounts per user.Reddit got two more people from their YC batch: Chris Slowe and\nAaron Swartz, and they too were unusually smart. Chris was just\nfinishing his PhD in physics at Harvard. Aaron was younger, a college\nfreshman, and even more anti-authority than Steve. It's not\nexaggerating to describe him as a martyr for what authority later\ndid to him.Slowly but inexorably Reddit's traffic grew. At first the numbers\nwere so small they were hard to distinguish from background noise.\nBut within a few weeks it was clear that there was a core of real\nusers returning regularly to the site. And although all kinds of\nthings have happened to Reddit the company in the years since,\nReddit the site never looked back.Reddit the site (and now app) is such a fundamentally useful thing\nthat it's almost unkillable. Which is why, despite a long stretch\nafter Steve left when the management strategy ranged from benign\nneglect to spectacular blunders, traffic just kept growing. You\ncan't do that with most companies. Most companies you take your eye\noff the ball for six months and you're in deep trouble. But Reddit\nwas special, and when Steve came back in 2015, I knew the world was\nin for a surprise.People thought they had Reddit's number: one of the players in\nSilicon Valley, but not one of the big ones. But those who knew\nwhat had been going on behind the scenes knew there was more to the\nstory than this. If Reddit could grow to the size it had with\nmanagement that was harmless at best, what could it do if Steve\ncame back? We now know the answer to that question. Or at least a\nlower bound on the answer. Steve is not out of ideas yet."
        ],
        "source_file": null
    },
    {
        "input": "What was Steve and Alexis's initial concept for a cellphone-based fast-food ordering system?",
        "actual_output": null,
        "expected_output": "Steve and Alexis's initial concept for a cellphone-based fast-food ordering system involved creating a way to order fast food using cellphones. This idea would require making deals with cell carriers and fast food chains to launch, but given the technology and circumstances at the time (before smartphones), it was deemed impractical and was eventually dropped.",
        "context": [
            "The Reddits\n\nMarch 2024I met the Reddits before we even started Y Combinator. In fact they\nwere one of the reasons we started it.YC grew out of a talk I gave to the Harvard Computer Society (the\nundergrad computer club) about how to start a startup. Everyone\nelse in the audience was probably local, but Steve and Alexis came\nup on the train from the University of Virginia, where they were\nseniors. Since they'd come so far I agreed to meet them for coffee.\nThey told me about the startup idea we'd later fund them to drop:\na way to order fast food on your cellphone.This was before smartphones. They'd have had to make deals with\ncell carriers and fast food chains just to get it launched. So it\nwas not going to happen. It still doesn't exist, 19 years later.\nBut I was impressed with their brains and their energy. In fact I\nwas so impressed with them and some of the other people I met at\nthat talk that I decided to start something to fund them. A few\ndays later I told Steve and Alexis that we were starting Y Combinator,\nand encouraged them to apply.That first batch we didn't have any way to identify applicants, so\nwe made up nicknames for them. The Reddits were the \"Cell food\nmuffins.\" \"Muffin\" is a term of endearment Jessica uses for things\nlike small dogs and two year olds. So that gives you some idea what\nkind of impression Steve and Alexis made in those days. They had\nthe look of slightly ruffled surprise that baby birds have.Their idea was bad though. And since we thought then that we were\nfunding ideas rather than founders, we rejected them. But we felt\nbad about it. Jessica was sad that we'd rejected the muffins. And\nit seemed wrong to me to turn down the people we'd been inspired\nto start YC to fund.I don't think the startup sense of the word \"pivot\" had been invented\nyet, but we wanted to fund Steve and Alexis, so if their idea was\nbad, they'd have to work on something else. And I knew what else.\nIn those days there was a site called Delicious where you could\nsave links. It had a page called del.icio.us/popular that listed\nthe most-saved links, and people were using this page as a de facto\nReddit. I knew because a lot of the traffic to my site was coming\nfrom it. There needed to be something like del.icio.us/popular, but\ndesigned for sharing links instead of being a byproduct of saving\nthem.So I called Steve and Alexis and said that we liked them, just not\ntheir idea, so we'd fund them if they'd work on something else.\nThey were on the train home to Virginia at that point. They got off\nat the next station and got on the next train north, and by the end\nof the day were committed to working on what's now called Reddit.They would have liked to call it Snoo, as in \"What snoo?\" But\nsnoo.com was too expensive, so they settled for calling the mascot\nSnoo and picked a name for the site that wasn't registered. Early\non Reddit was just a provisional name, or so they told me at least,\nbut it's probably too late to change it now.As with all the really great startups, there's an uncannily close\nmatch between the company and the founders. Steve in particular.\nReddit has a certain personality — curious, skeptical, ready to\nbe amused — and that personality is Steve's.Steve will roll his eyes at this, but he's an intellectual; he's\ninterested in ideas for their own sake. That was how he came to be\nin that audience in Cambridge in the first place. He knew me because\nhe was interested in a programming language I've written about\ncalled Lisp, and Lisp is one of those languages few people learn\nexcept out of intellectual curiosity. Steve's kind of vacuum-cleaner\ncuriosity is exactly what you want when you're starting a site\nthat's a list of links to literally anything interesting.Steve was not a big fan of authority, so he also liked the idea of\na site without editors. In those days the top forum for programmers\nwas a site called Slashdot. It was a lot like Reddit, except the\nstories on the frontpage were chosen by human moderators. And though\nthey did a good job, that one small difference turned out to be a\nbig difference. Being driven by user submissions meant Reddit was\nfresher than Slashdot. News there was newer, and users will always\ngo where the newest news is.I pushed the Reddits to launch fast. A version one didn't need to\nbe more than a couple hundred lines of code. How could that take\nmore than a week or two to build? And they did launch comparatively\nfast, about three weeks into the first YC batch. The first users\nwere Steve, Alexis, me, and some of their YC batchmates and college\nfriends. It turns out you don't need that many users to collect a\ndecent list of interesting links, especially if you have multiple\naccounts per user.Reddit got two more people from their YC batch: Chris Slowe and\nAaron Swartz, and they too were unusually smart. Chris was just\nfinishing his PhD in physics at Harvard. Aaron was younger, a college\nfreshman, and even more anti-authority than Steve. It's not\nexaggerating to describe him as a martyr for what authority later\ndid to him.Slowly but inexorably Reddit's traffic grew. At first the numbers\nwere so small they were hard to distinguish from background noise.\nBut within a few weeks it was clear that there was a core of real\nusers returning regularly to the site. And although all kinds of\nthings have happened to Reddit the company in the years since,\nReddit the site never looked back.Reddit the site (and now app) is such a fundamentally useful thing\nthat it's almost unkillable. Which is why, despite a long stretch\nafter Steve left when the management strategy ranged from benign\nneglect to spectacular blunders, traffic just kept growing. You\ncan't do that with most companies. Most companies you take your eye\noff the ball for six months and you're in deep trouble. But Reddit\nwas special, and when Steve came back in 2015, I knew the world was\nin for a surprise.People thought they had Reddit's number: one of the players in\nSilicon Valley, but not one of the big ones. But those who knew\nwhat had been going on behind the scenes knew there was more to the\nstory than this. If Reddit could grow to the size it had with\nmanagement that was harmless at best, what could it do if Steve\ncame back? We now know the answer to that question. Or at least a\nlower bound on the answer. Steve is not out of ideas yet."
        ],
        "source_file": null
    },
    {
        "input": "Compare 'founder mode' with 'manager mode' in running companies, as explained by Brian Chesky.",
        "actual_output": null,
        "expected_output": "Founder mode and manager mode represent two distinct approaches to running companies, as highlighted by Brian Chesky. In founder mode, the CEO engages directly with all levels of the company, not just through direct reports, enabling more hands-on involvement and understanding. This approach allows for dynamic interactions, such as \"skip-level\" meetings, and encourages innovation and agility, akin to how Steve Jobs managed Apple. Conversely, manager mode follows a more traditional corporate structure where a CEO manages through a hierarchical system, treating departments as black boxes managed by direct reports. This can lead to a disconnect and reliance on professional managers who may prioritize maintaining appearances over genuine progress. Founder mode breaks traditional hierarchies and permits a more personalized and influential leadership style that founders often find more effective for scaling companies.",
        "context": [
            "Founder Mode\n\nSeptember 2024At a YC event last week Brian Chesky gave a talk that everyone who\nwas there will remember. Most founders I talked to afterward said\nit was the best they'd ever heard. Ron Conway, for the first time\nin his life, forgot to take notes. I'm not going to try to reproduce\nit here. Instead I want to talk about a question it raised.The theme of Brian's talk was that the conventional wisdom about\nhow to run larger companies is mistaken. As Airbnb grew, well-meaning\npeople advised him that he had to run the company in a certain way\nfor it to scale. Their advice could be optimistically summarized\nas \"hire good people and give them room to do their jobs.\" He\nfollowed this advice and the results were disastrous. So he had to\nfigure out a better way on his own, which he did partly by studying\nhow Steve Jobs ran Apple. So far it seems to be working. Airbnb's\nfree cash flow margin is now among the best in Silicon Valley.The audience at this event included a lot of the most successful\nfounders we've funded, and one after another said that the same\nthing had happened to them. They'd been given the same advice about\nhow to run their companies as they grew, but instead of helping\ntheir companies, it had damaged them.Why was everyone telling these founders the wrong thing? That was\nthe big mystery to me. And after mulling it over for a bit I figured\nout the answer: what they were being told was how to run a company\nyou hadn't founded — how to run a company if you're merely a\nprofessional manager. But this m.o. is so much less effective that\nto founders it feels broken. There are things founders can do that\nmanagers can't, and not doing them feels wrong to founders, because\nit is.In effect there are two different ways to run a company: founder\nmode and manager mode. Till now most people even in Silicon Valley\nhave implicitly assumed that scaling a startup meant switching to\nmanager mode. But we can infer the existence of another mode from\nthe dismay of founders who've tried it, and the success of their\nattempts to escape from it.There are as far as I know no books specifically about founder mode.\nBusiness schools don't know it exists. All we have so far are the\nexperiments of individual founders who've been figuring it out for\nthemselves. But now that we know what we're looking for, we can\nsearch for it. I hope in a few years founder mode will be as well\nunderstood as manager mode. We can already guess at some of the\nways it will differ.The way managers are taught to run companies seems to be like modular\ndesign in the sense that you treat subtrees of the org chart as\nblack boxes. You tell your direct reports what to do, and it's up\nto them to figure out how. But you don't get involved in the details\nof what they do. That would be micromanaging them, which is bad.Hire good people and give them room to do their jobs. Sounds great\nwhen it's described that way, doesn't it? Except in practice, judging\nfrom the report of founder after founder, what this often turns out\nto mean is: hire professional fakers and let them drive the company\ninto the ground.One theme I noticed both in Brian's talk and when talking to founders\nafterward was the idea of being gaslit. Founders feel like they're\nbeing gaslit from both sides — by the people telling them they\nhave to run their companies like managers, and by the people working\nfor them when they do. Usually when everyone around you disagrees\nwith you, your default assumption should be that you're mistaken.\nBut this is one of the rare exceptions. VCs who haven't been founders\nthemselves don't know how founders should run companies, and C-level\nexecs, as a class, include some of the most skillful liars in the\nworld.\n[1]Whatever founder mode consists of, it's pretty clear that it's going\nto break the principle that the CEO should engage with the company\nonly via his or her direct reports. \"Skip-level\" meetings will\nbecome the norm instead of a practice so unusual that there's a\nname for it. And once you abandon that constraint there are a huge\nnumber of permutations to choose from.For example, Steve Jobs used to run an annual retreat for what he\nconsidered the 100 most important people at Apple, and these were\nnot the 100 people highest on the org chart. Can you imagine the\nforce of will it would take to do this at the average company? And\nyet imagine how useful such a thing could be. It could make a big\ncompany feel like a startup. Steve presumably wouldn't have kept\nhaving these retreats if they didn't work. But I've never heard of\nanother company doing this. So is it a good idea, or a bad one? We\nstill don't know. That's how little we know about founder mode.\n[2]Obviously founders can't keep running a 2000 person company the way\nthey ran it when it had 20. There's going to have to be some amount\nof delegation. Where the borders of autonomy end up, and how sharp\nthey are, will probably vary from company to company. They'll even\nvary from time to time within the same company, as managers earn\ntrust. So founder mode will be more complicated than manager mode.\nBut it will also work better. We already know that from the examples\nof individual founders groping their way toward it.Indeed, another prediction I'll make about founder mode is that\nonce we figure out what it is, we'll find that a number of individual\nfounders were already most of the way there — except that in doing\nwhat they did they were regarded by many as eccentric or worse.\n[3]Curiously enough it's an encouraging thought that we still know so\nlittle about founder mode. Look at what founders have achieved\nalready, and yet they've achieved this against a headwind of bad\nadvice. Imagine what they'll do once we can tell them how to run\ntheir companies like Steve Jobs instead of John Sculley.Notes[1]\nThe more diplomatic way of phrasing this statement would be\nto say that experienced C-level execs are often very skilled at\nmanaging up. And I don't think anyone with knowledge of this world\nwould dispute that.[2]\nIf the practice of having such retreats became so widespread\nthat even mature companies dominated by politics started to do it,\nwe could quantify the senescence of companies by the average depth\non the org chart of those invited.[3]\nI also have another less optimistic prediction: as soon as\nthe concept of founder mode becomes established, people will start\nmisusing it. Founders who are unable to delegate even things they\nshould will use founder mode as the excuse. Or managers who aren't\nfounders will decide they should try to act like founders. That may\neven work, to some extent, but the results will be messy when it\ndoesn't; the modular approach does at least limit the damage a bad\nCEO can do.Thanks to Brian Chesky, Patrick Collison, \nRon Conway, Jessica\nLivingston, Elon Musk, Ryan Petersen, Harj Taggar, and Garry Tan\nfor reading drafts of this."
        ],
        "source_file": null
    },
    {
        "input": "How did Chesky's perspective on managerial practices contrast with traditional advice for scalable growth?",
        "actual_output": null,
        "expected_output": "Brian Chesky's perspective on managerial practices contrasted with traditional advice for scalable growth by challenging the conventional wisdom of \"hire good people and give them room to do their jobs.\" He found this approach disastrous for Airbnb and realized it was more suitable for professional managers rather than founders. Chesky's success came from adopting a \"founder mode,\" inspired partly by Steve Jobs, which involves more direct engagement beyond just direct reports, as exemplified by practices like his annual retreats for the most important people at Apple. This approach emphasizes a more hands-on and involved leadership style, breaking from the traditional modular design management methods that risk letting unsuitable leadership drive a company into the ground.",
        "context": [
            "Founder Mode\n\nSeptember 2024At a YC event last week Brian Chesky gave a talk that everyone who\nwas there will remember. Most founders I talked to afterward said\nit was the best they'd ever heard. Ron Conway, for the first time\nin his life, forgot to take notes. I'm not going to try to reproduce\nit here. Instead I want to talk about a question it raised.The theme of Brian's talk was that the conventional wisdom about\nhow to run larger companies is mistaken. As Airbnb grew, well-meaning\npeople advised him that he had to run the company in a certain way\nfor it to scale. Their advice could be optimistically summarized\nas \"hire good people and give them room to do their jobs.\" He\nfollowed this advice and the results were disastrous. So he had to\nfigure out a better way on his own, which he did partly by studying\nhow Steve Jobs ran Apple. So far it seems to be working. Airbnb's\nfree cash flow margin is now among the best in Silicon Valley.The audience at this event included a lot of the most successful\nfounders we've funded, and one after another said that the same\nthing had happened to them. They'd been given the same advice about\nhow to run their companies as they grew, but instead of helping\ntheir companies, it had damaged them.Why was everyone telling these founders the wrong thing? That was\nthe big mystery to me. And after mulling it over for a bit I figured\nout the answer: what they were being told was how to run a company\nyou hadn't founded — how to run a company if you're merely a\nprofessional manager. But this m.o. is so much less effective that\nto founders it feels broken. There are things founders can do that\nmanagers can't, and not doing them feels wrong to founders, because\nit is.In effect there are two different ways to run a company: founder\nmode and manager mode. Till now most people even in Silicon Valley\nhave implicitly assumed that scaling a startup meant switching to\nmanager mode. But we can infer the existence of another mode from\nthe dismay of founders who've tried it, and the success of their\nattempts to escape from it.There are as far as I know no books specifically about founder mode.\nBusiness schools don't know it exists. All we have so far are the\nexperiments of individual founders who've been figuring it out for\nthemselves. But now that we know what we're looking for, we can\nsearch for it. I hope in a few years founder mode will be as well\nunderstood as manager mode. We can already guess at some of the\nways it will differ.The way managers are taught to run companies seems to be like modular\ndesign in the sense that you treat subtrees of the org chart as\nblack boxes. You tell your direct reports what to do, and it's up\nto them to figure out how. But you don't get involved in the details\nof what they do. That would be micromanaging them, which is bad.Hire good people and give them room to do their jobs. Sounds great\nwhen it's described that way, doesn't it? Except in practice, judging\nfrom the report of founder after founder, what this often turns out\nto mean is: hire professional fakers and let them drive the company\ninto the ground.One theme I noticed both in Brian's talk and when talking to founders\nafterward was the idea of being gaslit. Founders feel like they're\nbeing gaslit from both sides — by the people telling them they\nhave to run their companies like managers, and by the people working\nfor them when they do. Usually when everyone around you disagrees\nwith you, your default assumption should be that you're mistaken.\nBut this is one of the rare exceptions. VCs who haven't been founders\nthemselves don't know how founders should run companies, and C-level\nexecs, as a class, include some of the most skillful liars in the\nworld.\n[1]Whatever founder mode consists of, it's pretty clear that it's going\nto break the principle that the CEO should engage with the company\nonly via his or her direct reports. \"Skip-level\" meetings will\nbecome the norm instead of a practice so unusual that there's a\nname for it. And once you abandon that constraint there are a huge\nnumber of permutations to choose from.For example, Steve Jobs used to run an annual retreat for what he\nconsidered the 100 most important people at Apple, and these were\nnot the 100 people highest on the org chart. Can you imagine the\nforce of will it would take to do this at the average company? And\nyet imagine how useful such a thing could be. It could make a big\ncompany feel like a startup. Steve presumably wouldn't have kept\nhaving these retreats if they didn't work. But I've never heard of\nanother company doing this. So is it a good idea, or a bad one? We\nstill don't know. That's how little we know about founder mode.\n[2]Obviously founders can't keep running a 2000 person company the way\nthey ran it when it had 20. There's going to have to be some amount\nof delegation. Where the borders of autonomy end up, and how sharp\nthey are, will probably vary from company to company. They'll even\nvary from time to time within the same company, as managers earn\ntrust. So founder mode will be more complicated than manager mode.\nBut it will also work better. We already know that from the examples\nof individual founders groping their way toward it.Indeed, another prediction I'll make about founder mode is that\nonce we figure out what it is, we'll find that a number of individual\nfounders were already most of the way there — except that in doing\nwhat they did they were regarded by many as eccentric or worse.\n[3]Curiously enough it's an encouraging thought that we still know so\nlittle about founder mode. Look at what founders have achieved\nalready, and yet they've achieved this against a headwind of bad\nadvice. Imagine what they'll do once we can tell them how to run\ntheir companies like Steve Jobs instead of John Sculley.Notes[1]\nThe more diplomatic way of phrasing this statement would be\nto say that experienced C-level execs are often very skilled at\nmanaging up. And I don't think anyone with knowledge of this world\nwould dispute that.[2]\nIf the practice of having such retreats became so widespread\nthat even mature companies dominated by politics started to do it,\nwe could quantify the senescence of companies by the average depth\non the org chart of those invited.[3]\nI also have another less optimistic prediction: as soon as\nthe concept of founder mode becomes established, people will start\nmisusing it. Founders who are unable to delegate even things they\nshould will use founder mode as the excuse. Or managers who aren't\nfounders will decide they should try to act like founders. That may\neven work, to some extent, but the results will be messy when it\ndoesn't; the modular approach does at least limit the damage a bad\nCEO can do.Thanks to Brian Chesky, Patrick Collison, \nRon Conway, Jessica\nLivingston, Elon Musk, Ryan Petersen, Harj Taggar, and Garry Tan\nfor reading drafts of this."
        ],
        "source_file": null
    },
    {
        "input": "Examine the foundational tenets of March 2025 life philosophy focusing on altruism, stewardship, and innovation.",
        "actual_output": null,
        "expected_output": "The foundational tenets of the March 2025 life philosophy prioritize helping others, taking care of the world, and making good new things. Altruism and stewardship are seen as duties: helping people and caring for the world are essential responsibilities. Innovation, or making good new things, is seen as a means to live to one's full potential. While traditional philosophies emphasize virtues like wisdom and honesty, the March 2025 philosophy highlights creation and newness, suggesting that true comprehension and progress come from the ability to innovate.",
        "context": [
            "What to Do\n\nMarch 2025What should one do? That may seem a strange question, but it's not\nmeaningless or unanswerable. It's the sort of question kids ask\nbefore they learn not to ask big questions. I only came across it\nmyself in the process of investigating something else. But once I\ndid, I thought I should at least try to answer it.So what should one do? One should help people, and take care of\nthe world. Those two are obvious. But is there anything else? When\nI ask that, the answer that pops up is Make good new things.I can't prove that one should do this, any more than I can prove\nthat one should help people or take care of the world. We're talking\nabout first principles here. But I can explain why this principle\nmakes sense. The most impressive thing humans can do is to think.\nIt may be the most impressive thing that can be done. And the best\nkind of thinking, or more precisely the best proof that one has\nthought well, is to make good new things.I mean new things in a very general sense. Newton's physics was a\ngood new thing. Indeed, the first version of this principle was to\nhave good new ideas. But that didn't seem general enough: it didn't\ninclude making art or music, for example, except insofar as they\nembody new ideas. And while they may embody new ideas, that's not\nall they embody, unless you stretch the word \"idea\" so uselessly\nthin that it includes everything that goes through your nervous\nsystem.Even for ideas that one has consciously, though, I prefer the\nphrasing \"make good new things.\" There are other ways to describe\nthe best kind of thinking. To make discoveries, for example, or to\nunderstand something more deeply than others have. But how well do\nyou understand something if you can't make a model of it, or write\nabout it? Indeed, trying to express what you understand is not just\na way to prove that you understand it, but a way to understand it\nbetter.Another reason I like this phrasing is that it biases us toward\ncreation. It causes us to prefer the kind of ideas that are naturally\nseen as making things rather than, say, making critical observations\nabout things other people have made. Those are ideas too, and\nsometimes valuable ones, but it's easy to trick oneself into believing\nthey're more valuable than they are. Criticism seems sophisticated,\nand making new things often seems awkward, especially at first; and\nyet it's precisely those first steps that are most rare and valuable.Is newness essential? I think so. Obviously it's essential in\nscience. If you copied a paper of someone else's and published it\nas your own, it would seem not merely unimpressive but dishonest.\nAnd it's similar in the arts. A copy of a good painting can be a\npleasing thing, but it's not impressive in the way the original\nwas. Which in turn implies it's not impressive to make the same\nthing over and over, however well; you're just copying yourself.Note though that we're talking about a different kind of should\nwith this principle. Taking care of people and the world are shoulds\nin the sense that they're one's duty, but making good new things\nis a should in the sense that this is how to live to one's full\npotential. Historically most rules about how to live have been a\nmix of both kinds of should, though usually with more of the former\nthan the latter. \n[1]For most of history the question \"What should one do?\" got much the\nsame answer everywhere, whether you asked Cicero or Confucius. You\nshould be wise, brave, honest, temperate, and just, uphold tradition,\nand serve the public interest. There was a long stretch where in\nsome parts of the world the answer became \"Serve God,\" but in\npractice it was still considered good to be wise, brave, honest,\ntemperate, and just, uphold tradition, and serve the public interest.\nAnd indeed this recipe would have seemed right to most Victorians.\nBut there's nothing in it about taking care of the world or making\nnew things, and that's a bit worrying, because it seems like this\nquestion should be a timeless one. The answer shouldn't change much.I'm not too worried that the traditional answers don't mention\ntaking care of the world. Obviously people only started to care\nabout that once it became clear we could ruin it. But how can making\ngood new things be important if the traditional answers don't mention\nit?The traditional answers were answers to a slightly different question.\nThey were answers to the question of how to be, rather than what\nto do. The audience didn't have a lot of choice about what to do.\nThe audience up till recent centuries was the landowning class,\nwhich was also the political class. They weren't choosing between\ndoing physics and writing novels. Their work was foreordained:\nmanage their estates, participate in politics, fight when necessary.\nIt was ok to do certain other kinds of work in one's spare time,\nbut ideally one didn't have any. Cicero's De Officiis is one of the\ngreat classical answers to the question of how to live, and in it\nhe explicitly says that he wouldn't even be writing it if he hadn't\nbeen excluded from public life by recent political upheavals.\n[2]There were of course people doing what we would now call \"original\nwork,\" and they were often admired for it, but they weren't seen\nas models. Archimedes knew that he was the first to prove that a\nsphere has 2/3 the volume of the smallest enclosing cylinder and\nwas very pleased about it. But you don't find ancient writers urging\ntheir readers to emulate him. They regarded him more as a prodigy\nthan a model.Now many more of us can follow Archimedes's example and devote most\nof our attention to one kind of work. He turned out to be a model\nafter all, along with a collection of other people that his\ncontemporaries would have found it strange to treat as a distinct\ngroup, because the vein of people making new things ran at right\nangles to the social hierarchy.What kinds of new things count? I'd rather leave that question to\nthe makers of them. It would be a risky business to try to define\nany kind of threshold, because new kinds of work are often despised\nat first. Raymond Chandler was writing literal pulp fiction, and\nhe's now recognized as one of the best writers of the twentieth\ncentury. Indeed this pattern is so common that you can use it as a\nrecipe: if you're excited about some kind of work that's not\nconsidered prestigious and you can explain what everyone else is\noverlooking about it, then this is not merely a kind of work that's\nok to do, but one to seek out.The other reason I wouldn't want to define any thresholds is that\nwe don't need them. The kind of people who make good new things \ndon't need rules to keep them honest.So there's my guess at a set of principles to live by: take care\nof people and the world, and make good new things. Different people\nwill do these to varying degrees. There will presumably be lots who\nfocus entirely on taking care of people. There will be a few who\nfocus mostly on making new things. But even if you're one of those,\nyou should at least make sure that the new things you make don't\nnet harm people or the world. And if you go a step further and\ntry to make things that help them, you may find you're ahead on the\ntrade. You'll be more constrained in what you can make, but you'll\nmake it with more energy.On the other hand, if you make something amazing, you'll often be\nhelping people or the world even if you didn't mean to. Newton was\ndriven by curiosity and ambition, not by any practical effect his\nwork might have, and yet the practical effect of his work has been\nenormous. And this seems the rule rather than the exception. So\nif you think you can make something amazing, you should probably\njust go ahead and do it.Notes[1]\nWe could treat all three as the same kind of should by saying\nthat it's one's duty to live well — for example by saying, as some\nChristians have, that it's one's duty to make the most of one's\nGod-given gifts. But this seems one of those casuistries people\ninvented to evade the stern requirements of religion: it was permissible to\nspend time studying math instead of praying or performing acts of\ncharity because otherwise you were rejecting a gift God had given\nyou. A useful casuistry no doubt, but we don't need it.We could also combine the first two principles, since people are\npart of the world. Why should our species get special treatment?\nI won't try to justify this choice, but I'm skeptical that anyone\nwho claims to think differently actually lives according to their\nprinciples.[2]\nConfucius was also excluded from public life after ending up\non the losing end of a power struggle, and presumably he too would\nnot be so famous now if it hadn't been for this long stretch of\nenforced leisure.Thanks to Trevor Blackwell, Jessica \nLivingston, and Robert Morris for reading drafts of this."
        ],
        "source_file": null
    },
    {
        "input": "How do novel creations fulfill one's potential, surpassing historical norms of wisdom and bravery?",
        "actual_output": null,
        "expected_output": "Novel creations fulfill one's potential by allowing individuals to engage in the most impressive human capacity: thinking and innovation. While historical norms emphasized wisdom and bravery, creating something new pushes individuals to expand their understanding and capabilities beyond those traditional values. Creating new things is a way of living to one's full potential because it involves not just understanding but actualizing ideas into tangible outcomes that can impact the world. Unlike mere adherence to wisdom and bravery, creating novel works fosters a deeper and more active engagement with the world, often resulting in unexpected benefits for society, as exemplified by figures like Newton and Archimedes whose works fundamentally shaped modern understanding despite their initial motivations.",
        "context": [
            "What to Do\n\nMarch 2025What should one do? That may seem a strange question, but it's not\nmeaningless or unanswerable. It's the sort of question kids ask\nbefore they learn not to ask big questions. I only came across it\nmyself in the process of investigating something else. But once I\ndid, I thought I should at least try to answer it.So what should one do? One should help people, and take care of\nthe world. Those two are obvious. But is there anything else? When\nI ask that, the answer that pops up is Make good new things.I can't prove that one should do this, any more than I can prove\nthat one should help people or take care of the world. We're talking\nabout first principles here. But I can explain why this principle\nmakes sense. The most impressive thing humans can do is to think.\nIt may be the most impressive thing that can be done. And the best\nkind of thinking, or more precisely the best proof that one has\nthought well, is to make good new things.I mean new things in a very general sense. Newton's physics was a\ngood new thing. Indeed, the first version of this principle was to\nhave good new ideas. But that didn't seem general enough: it didn't\ninclude making art or music, for example, except insofar as they\nembody new ideas. And while they may embody new ideas, that's not\nall they embody, unless you stretch the word \"idea\" so uselessly\nthin that it includes everything that goes through your nervous\nsystem.Even for ideas that one has consciously, though, I prefer the\nphrasing \"make good new things.\" There are other ways to describe\nthe best kind of thinking. To make discoveries, for example, or to\nunderstand something more deeply than others have. But how well do\nyou understand something if you can't make a model of it, or write\nabout it? Indeed, trying to express what you understand is not just\na way to prove that you understand it, but a way to understand it\nbetter.Another reason I like this phrasing is that it biases us toward\ncreation. It causes us to prefer the kind of ideas that are naturally\nseen as making things rather than, say, making critical observations\nabout things other people have made. Those are ideas too, and\nsometimes valuable ones, but it's easy to trick oneself into believing\nthey're more valuable than they are. Criticism seems sophisticated,\nand making new things often seems awkward, especially at first; and\nyet it's precisely those first steps that are most rare and valuable.Is newness essential? I think so. Obviously it's essential in\nscience. If you copied a paper of someone else's and published it\nas your own, it would seem not merely unimpressive but dishonest.\nAnd it's similar in the arts. A copy of a good painting can be a\npleasing thing, but it's not impressive in the way the original\nwas. Which in turn implies it's not impressive to make the same\nthing over and over, however well; you're just copying yourself.Note though that we're talking about a different kind of should\nwith this principle. Taking care of people and the world are shoulds\nin the sense that they're one's duty, but making good new things\nis a should in the sense that this is how to live to one's full\npotential. Historically most rules about how to live have been a\nmix of both kinds of should, though usually with more of the former\nthan the latter. \n[1]For most of history the question \"What should one do?\" got much the\nsame answer everywhere, whether you asked Cicero or Confucius. You\nshould be wise, brave, honest, temperate, and just, uphold tradition,\nand serve the public interest. There was a long stretch where in\nsome parts of the world the answer became \"Serve God,\" but in\npractice it was still considered good to be wise, brave, honest,\ntemperate, and just, uphold tradition, and serve the public interest.\nAnd indeed this recipe would have seemed right to most Victorians.\nBut there's nothing in it about taking care of the world or making\nnew things, and that's a bit worrying, because it seems like this\nquestion should be a timeless one. The answer shouldn't change much.I'm not too worried that the traditional answers don't mention\ntaking care of the world. Obviously people only started to care\nabout that once it became clear we could ruin it. But how can making\ngood new things be important if the traditional answers don't mention\nit?The traditional answers were answers to a slightly different question.\nThey were answers to the question of how to be, rather than what\nto do. The audience didn't have a lot of choice about what to do.\nThe audience up till recent centuries was the landowning class,\nwhich was also the political class. They weren't choosing between\ndoing physics and writing novels. Their work was foreordained:\nmanage their estates, participate in politics, fight when necessary.\nIt was ok to do certain other kinds of work in one's spare time,\nbut ideally one didn't have any. Cicero's De Officiis is one of the\ngreat classical answers to the question of how to live, and in it\nhe explicitly says that he wouldn't even be writing it if he hadn't\nbeen excluded from public life by recent political upheavals.\n[2]There were of course people doing what we would now call \"original\nwork,\" and they were often admired for it, but they weren't seen\nas models. Archimedes knew that he was the first to prove that a\nsphere has 2/3 the volume of the smallest enclosing cylinder and\nwas very pleased about it. But you don't find ancient writers urging\ntheir readers to emulate him. They regarded him more as a prodigy\nthan a model.Now many more of us can follow Archimedes's example and devote most\nof our attention to one kind of work. He turned out to be a model\nafter all, along with a collection of other people that his\ncontemporaries would have found it strange to treat as a distinct\ngroup, because the vein of people making new things ran at right\nangles to the social hierarchy.What kinds of new things count? I'd rather leave that question to\nthe makers of them. It would be a risky business to try to define\nany kind of threshold, because new kinds of work are often despised\nat first. Raymond Chandler was writing literal pulp fiction, and\nhe's now recognized as one of the best writers of the twentieth\ncentury. Indeed this pattern is so common that you can use it as a\nrecipe: if you're excited about some kind of work that's not\nconsidered prestigious and you can explain what everyone else is\noverlooking about it, then this is not merely a kind of work that's\nok to do, but one to seek out.The other reason I wouldn't want to define any thresholds is that\nwe don't need them. The kind of people who make good new things \ndon't need rules to keep them honest.So there's my guess at a set of principles to live by: take care\nof people and the world, and make good new things. Different people\nwill do these to varying degrees. There will presumably be lots who\nfocus entirely on taking care of people. There will be a few who\nfocus mostly on making new things. But even if you're one of those,\nyou should at least make sure that the new things you make don't\nnet harm people or the world. And if you go a step further and\ntry to make things that help them, you may find you're ahead on the\ntrade. You'll be more constrained in what you can make, but you'll\nmake it with more energy.On the other hand, if you make something amazing, you'll often be\nhelping people or the world even if you didn't mean to. Newton was\ndriven by curiosity and ambition, not by any practical effect his\nwork might have, and yet the practical effect of his work has been\nenormous. And this seems the rule rather than the exception. So\nif you think you can make something amazing, you should probably\njust go ahead and do it.Notes[1]\nWe could treat all three as the same kind of should by saying\nthat it's one's duty to live well — for example by saying, as some\nChristians have, that it's one's duty to make the most of one's\nGod-given gifts. But this seems one of those casuistries people\ninvented to evade the stern requirements of religion: it was permissible to\nspend time studying math instead of praying or performing acts of\ncharity because otherwise you were rejecting a gift God had given\nyou. A useful casuistry no doubt, but we don't need it.We could also combine the first two principles, since people are\npart of the world. Why should our species get special treatment?\nI won't try to justify this choice, but I'm skeptical that anyone\nwho claims to think differently actually lives according to their\nprinciples.[2]\nConfucius was also excluded from public life after ending up\non the losing end of a power struggle, and presumably he too would\nnot be so famous now if it hadn't been for this long stretch of\nenforced leisure.Thanks to Trevor Blackwell, Jessica \nLivingston, and Robert Morris for reading drafts of this."
        ],
        "source_file": null
    },
    {
        "input": "In a world where passion leads to massive wealth, how might career choices change?",
        "actual_output": null,
        "expected_output": "In a world where passion leads to massive wealth, career choices would likely shift significantly. People would prioritize working on what interests them most, as aligning personal passion with economic gain is the most natural motivator. The emphasis on pursuing jobs just for financial security would decrease, and more individuals would explore careers in niche fields or start innovative ventures aligned with their interests. This could lead to diverse career paths, fostering creativity and innovation as people would feel more empowered to follow their authentic interests.",
        "context": [
            "When To Do What You Love\n\nSeptember 2024There's some debate about whether it's a good idea to \"follow your\npassion.\" In fact the question is impossible to answer with a simple\nyes or no. Sometimes you should and sometimes you shouldn't, but\nthe border between should and shouldn't is very complicated. The\nonly way to give a general answer is to trace it.When people talk about this question, there's always an implicit\n\"instead of.\" All other things being equal, why wouldn't you work\non what interests you the most? So even raising the question implies\nthat all other things aren't equal, and that you have to choose\nbetween working on what interests you the most and something else,\nlike what pays the best.And indeed if your main goal is to make money, you can't usually\nafford to work on what interests you the most. People pay you for\ndoing what they want, not what you want. But there's an obvious\nexception: when you both want the same thing. For example, if you\nlove football, and you're good enough at it, you can get paid a lot\nto play it.Of course the odds are against you in a case like football, because\nso many other people like playing it too. This is not to say you\nshouldn't try though. It depends how much ability you have and how\nhard you're willing to work.The odds are better when you have strange tastes: when you like\nsomething that pays well and that few other people like. For example,\nit's clear that Bill Gates truly loved running a software company.\nHe didn't just love programming, which a lot of people do. He loved\nwriting software for customers. That is a very strange taste indeed,\nbut if you have it, you can make a lot by indulging it.There are even some people who have a genuine intellectual interest\nin making money. This is distinct from mere greed. They just can't\nhelp noticing when something is mispriced, and can't help doing\nsomething about it. It's like a puzzle for them.\n[1]In fact there's an edge case here so spectacular that it turns all\nthe preceding advice on its head. If you want to make a really \nhuge\namount of money — hundreds of millions or even billions of dollars\n— it turns out to be very useful to work on what interests you the\nmost. The reason is not the extra motivation you get from doing\nthis, but that the way to make a really large amount of money is\nto start a startup, and working on what interests you is an excellent\nway to discover startup ideas.Many if not most of the biggest startups began as projects the\nfounders were doing for fun. Apple, Google, and Facebook all began\nthat way. Why is this pattern so common? Because the best ideas\ntend to be such outliers that you'd overlook them if you were\nconsciously looking for ways to make money. Whereas if you're young\nand good at technology, your unconscious instincts about what would\nbe interesting to work on are very well aligned with what needs to\nbe built.So there's something like a midwit peak for making money. If you\ndon't need to make much, you can work on whatever you're most\ninterested in; if you want to become moderately rich, you can't\nusually afford to; but if you want to become super rich, and you're\nyoung and good at technology, working on what you're most interested\nin becomes a good idea again.What if you're not sure what you want? What if you're attracted to\nthe idea of making money and more attracted to some kinds of work\nthan others, but neither attraction predominates? How do you break\nties?The key here is to understand that such ties are only apparent.\nWhen you have trouble choosing between following your interests and\nmaking money, it's never because you have complete knowledge of\nyourself and of the types of work you're choosing between, and the\noptions are perfectly balanced. When you can't decide which path\nto take, it's almost always due to ignorance. In fact you're usually\nsuffering from three kinds of ignorance simultaneously: you don't\nknow what makes you happy, what the various kinds of work are really\nlike, or how well you could do them. \n[2]In a way this ignorance is excusable. It's often hard to predict\nthese things, and no one even tells you that you need to. If you're\nambitious you're told you should go to college, and this is good\nadvice so far as it goes, but that's where it usually ends. No one\ntells you how to figure out what to work on, or how hard this can\nbe.What do you do in the face of uncertainty? Get more certainty. And\nprobably the best way to do that is to try working on things you're\ninterested in. That will get you more information about how interested\nyou are in them, how good you are at them, and how much scope they\noffer for ambition.Don't wait. Don't wait till the end of college to figure out what\nto work on. Don't even wait for internships during college. You\ndon't necessarily need a job doing x in order to work on x; often\nyou can just start doing it in some form yourself. And since figuring\nout what to work on is a problem that could take years to solve,\nthe sooner you start, the better.One useful trick for judging different kinds of work is to look at\nwho your colleagues will be. You'll become like whoever you work\nwith. Do you want to become like these people?Indeed, the difference in character between different kinds of work\nis magnified by the fact that everyone else is facing the same\ndecisions as you. If you choose a kind of work mainly for how well\nit pays, you'll be surrounded by other people who chose it for the\nsame reason, and that will make it even more soul-sucking than it\nseems from the outside. Whereas if you choose work you're genuinely\ninterested in, you'll be surrounded mostly by other people who are\ngenuinely interested in it, and that will make it extra inspiring.\n[3]The other thing you do in the face of uncertainty is to make choices\nthat are uncertainty-proof. The less sure you are about what to do,\nthe more important it is to choose options that give you more options\nin the future. I call this \"staying upwind.\" If you're unsure whether\nto major in math or economics, for example, choose math; math is\nupwind of economics in the sense that it will be easier to switch\nlater from math to economics than from economics to math.There's one case, though, where it's easy to say whether you should\nwork on what interests you the most: if you want to do \ngreat work.\nThis is not a sufficient condition for doing great work, but it is\na necessary one.There's a lot of selection bias in advice about whether to \"follow\nyour passion,\" and this is the reason. Most such advice comes from\npeople who are famously successful, and if you ask someone who's\nfamously successful how to do what they did, most will tell you\nthat you have to work on what you're most interested in. And this\nis in fact true.That doesn't mean it's the right advice for everyone. Not everyone\ncan do great work, or wants to. But if you do want to, the complicated\nquestion of whether or not to work on what interests you the most\nbecomes simple. The answer is yes. The root of great work is a sort\nof ambitious curiosity, and you can't manufacture that.Notes[1]\nThese examples show why it's a mistake to assume that economic\ninequality must be evidence of some kind of brokenness or unfairness.\nIt's obvious that different people have different interests, and\nthat some interests yield far more money than others, so how can\nit not be obvious that some people will end up much richer than\nothers? In a world where some people like to write enterprise\nsoftware and others like to make studio pottery, economic inequality\nis the natural outcome.[2]\nDifficulty choosing between interests is a different matter.\nThat's not always due to ignorance. It's often intrinsically\ndifficult. I still have trouble doing it.[3]\nYou can't always take people at their word on this. Since\nit's more prestigious to work on things you're interested in than\nto be driven by money, people who are driven mainly by money will\noften claim to be more interested in their work than they actually\nare. One way to test such claims is by doing the following thought\nexperiment: if their work didn't pay well, would they take day jobs\ndoing something else in order to do it in their spare time? Lots\nof mathematicians and scientists and engineers would. Historically\nlots have. But I don't think as many investment bankers would.This thought experiment is also useful for distinguishing between\nuniversity departments.Thanks to Trevor Blackwell, Paul Buchheit, \nJessica Livingston,\nRobert Morris, Harj Taggar, and Garry Tan for reading drafts of\nthis."
        ],
        "source_file": null
    },
    {
        "input": "How can startup founders leverage personal passions to discover innovative business ideas?",
        "actual_output": null,
        "expected_output": "Startup founders can leverage personal passions to discover innovative business ideas by following their interests and working on projects they find exciting. Many successful startups, such as Apple, Google, and Facebook, began as side projects driven by the founders' passion and curiosity. When founders focus on what truly interests them, they are more likely to identify unique ideas that might be overlooked if they were simply searching for ways to make money. Additionally, by engaging in activities they're passionate about, founders can gain deeper insights and develop novel solutions that align with genuine market needs. This alignment often leads to uncovering groundbreaking ideas for startups.",
        "context": [
            "When To Do What You Love\n\nSeptember 2024There's some debate about whether it's a good idea to \"follow your\npassion.\" In fact the question is impossible to answer with a simple\nyes or no. Sometimes you should and sometimes you shouldn't, but\nthe border between should and shouldn't is very complicated. The\nonly way to give a general answer is to trace it.When people talk about this question, there's always an implicit\n\"instead of.\" All other things being equal, why wouldn't you work\non what interests you the most? So even raising the question implies\nthat all other things aren't equal, and that you have to choose\nbetween working on what interests you the most and something else,\nlike what pays the best.And indeed if your main goal is to make money, you can't usually\nafford to work on what interests you the most. People pay you for\ndoing what they want, not what you want. But there's an obvious\nexception: when you both want the same thing. For example, if you\nlove football, and you're good enough at it, you can get paid a lot\nto play it.Of course the odds are against you in a case like football, because\nso many other people like playing it too. This is not to say you\nshouldn't try though. It depends how much ability you have and how\nhard you're willing to work.The odds are better when you have strange tastes: when you like\nsomething that pays well and that few other people like. For example,\nit's clear that Bill Gates truly loved running a software company.\nHe didn't just love programming, which a lot of people do. He loved\nwriting software for customers. That is a very strange taste indeed,\nbut if you have it, you can make a lot by indulging it.There are even some people who have a genuine intellectual interest\nin making money. This is distinct from mere greed. They just can't\nhelp noticing when something is mispriced, and can't help doing\nsomething about it. It's like a puzzle for them.\n[1]In fact there's an edge case here so spectacular that it turns all\nthe preceding advice on its head. If you want to make a really \nhuge\namount of money — hundreds of millions or even billions of dollars\n— it turns out to be very useful to work on what interests you the\nmost. The reason is not the extra motivation you get from doing\nthis, but that the way to make a really large amount of money is\nto start a startup, and working on what interests you is an excellent\nway to discover startup ideas.Many if not most of the biggest startups began as projects the\nfounders were doing for fun. Apple, Google, and Facebook all began\nthat way. Why is this pattern so common? Because the best ideas\ntend to be such outliers that you'd overlook them if you were\nconsciously looking for ways to make money. Whereas if you're young\nand good at technology, your unconscious instincts about what would\nbe interesting to work on are very well aligned with what needs to\nbe built.So there's something like a midwit peak for making money. If you\ndon't need to make much, you can work on whatever you're most\ninterested in; if you want to become moderately rich, you can't\nusually afford to; but if you want to become super rich, and you're\nyoung and good at technology, working on what you're most interested\nin becomes a good idea again.What if you're not sure what you want? What if you're attracted to\nthe idea of making money and more attracted to some kinds of work\nthan others, but neither attraction predominates? How do you break\nties?The key here is to understand that such ties are only apparent.\nWhen you have trouble choosing between following your interests and\nmaking money, it's never because you have complete knowledge of\nyourself and of the types of work you're choosing between, and the\noptions are perfectly balanced. When you can't decide which path\nto take, it's almost always due to ignorance. In fact you're usually\nsuffering from three kinds of ignorance simultaneously: you don't\nknow what makes you happy, what the various kinds of work are really\nlike, or how well you could do them. \n[2]In a way this ignorance is excusable. It's often hard to predict\nthese things, and no one even tells you that you need to. If you're\nambitious you're told you should go to college, and this is good\nadvice so far as it goes, but that's where it usually ends. No one\ntells you how to figure out what to work on, or how hard this can\nbe.What do you do in the face of uncertainty? Get more certainty. And\nprobably the best way to do that is to try working on things you're\ninterested in. That will get you more information about how interested\nyou are in them, how good you are at them, and how much scope they\noffer for ambition.Don't wait. Don't wait till the end of college to figure out what\nto work on. Don't even wait for internships during college. You\ndon't necessarily need a job doing x in order to work on x; often\nyou can just start doing it in some form yourself. And since figuring\nout what to work on is a problem that could take years to solve,\nthe sooner you start, the better.One useful trick for judging different kinds of work is to look at\nwho your colleagues will be. You'll become like whoever you work\nwith. Do you want to become like these people?Indeed, the difference in character between different kinds of work\nis magnified by the fact that everyone else is facing the same\ndecisions as you. If you choose a kind of work mainly for how well\nit pays, you'll be surrounded by other people who chose it for the\nsame reason, and that will make it even more soul-sucking than it\nseems from the outside. Whereas if you choose work you're genuinely\ninterested in, you'll be surrounded mostly by other people who are\ngenuinely interested in it, and that will make it extra inspiring.\n[3]The other thing you do in the face of uncertainty is to make choices\nthat are uncertainty-proof. The less sure you are about what to do,\nthe more important it is to choose options that give you more options\nin the future. I call this \"staying upwind.\" If you're unsure whether\nto major in math or economics, for example, choose math; math is\nupwind of economics in the sense that it will be easier to switch\nlater from math to economics than from economics to math.There's one case, though, where it's easy to say whether you should\nwork on what interests you the most: if you want to do \ngreat work.\nThis is not a sufficient condition for doing great work, but it is\na necessary one.There's a lot of selection bias in advice about whether to \"follow\nyour passion,\" and this is the reason. Most such advice comes from\npeople who are famously successful, and if you ask someone who's\nfamously successful how to do what they did, most will tell you\nthat you have to work on what you're most interested in. And this\nis in fact true.That doesn't mean it's the right advice for everyone. Not everyone\ncan do great work, or wants to. But if you do want to, the complicated\nquestion of whether or not to work on what interests you the most\nbecomes simple. The answer is yes. The root of great work is a sort\nof ambitious curiosity, and you can't manufacture that.Notes[1]\nThese examples show why it's a mistake to assume that economic\ninequality must be evidence of some kind of brokenness or unfairness.\nIt's obvious that different people have different interests, and\nthat some interests yield far more money than others, so how can\nit not be obvious that some people will end up much richer than\nothers? In a world where some people like to write enterprise\nsoftware and others like to make studio pottery, economic inequality\nis the natural outcome.[2]\nDifficulty choosing between interests is a different matter.\nThat's not always due to ignorance. It's often intrinsically\ndifficult. I still have trouble doing it.[3]\nYou can't always take people at their word on this. Since\nit's more prestigious to work on things you're interested in than\nto be driven by money, people who are driven mainly by money will\noften claim to be more interested in their work than they actually\nare. One way to test such claims is by doing the following thought\nexperiment: if their work didn't pay well, would they take day jobs\ndoing something else in order to do it in their spare time? Lots\nof mathematicians and scientists and engineers would. Historically\nlots have. But I don't think as many investment bankers would.This thought experiment is also useful for distinguishing between\nuniversity departments.Thanks to Trevor Blackwell, Paul Buchheit, \nJessica Livingston,\nRobert Morris, Harj Taggar, and Garry Tan for reading drafts of\nthis."
        ],
        "source_file": null
    },
    {
        "input": "Examine how the traits of resilience and imagination differentiate persistent individuals from obstinate characters.",
        "actual_output": null,
        "expected_output": "Resilience and imagination set persistent individuals apart from obstinate characters by enabling them to adapt and innovate in the face of challenges. Persistent people, equipped with resilience, can withstand setbacks without letting them affect their morale, while also maintaining the flexibility to alter their approach based on new information. Imagination fuels their creativity, allowing them to continuously generate new ideas and solutions. Conversely, obstinate individuals lack this adaptability and creativity, often sticking rigidly to their initial ideas despite contrary evidence, limiting their problem-solving effectiveness.",
        "context": [
            "The Right Kind of Stubborn\n\nJuly 2024Successful people tend to be persistent. New ideas often don't work\nat first, but they're not deterred. They keep trying and eventually\nfind something that does.Mere obstinacy, on the other hand, is a recipe for failure. Obstinate\npeople are so annoying. They won't listen. They beat their heads\nagainst a wall and get nowhere.But is there any real difference between these two cases? Are\npersistent and obstinate people actually behaving differently? Or\nare they doing the same thing, and we just label them later as\npersistent or obstinate depending on whether they turned out to be\nright or not?If that's the only difference then there's nothing to be learned\nfrom the distinction. Telling someone to be persistent rather than\nobstinate would just be telling them to be right rather than wrong,\nand they already know that. Whereas if persistence and obstinacy\nare actually different kinds of behavior, it would be worthwhile\nto tease them apart.\n[1]I've talked to a lot of determined people, and it seems to me that\nthey're different kinds of behavior. I've often walked away from a\nconversation thinking either \"Wow, that guy is determined\" or \"Damn,\nthat guy is stubborn,\" and I don't think I'm just talking about\nwhether they seemed right or not. That's part of it, but not all\nof it.There's something annoying about the obstinate that's not simply\ndue to being mistaken. They won't listen. And that's not true of\nall determined people. I can't think of anyone more determined than\nthe Collison brothers, and when you point out a problem to them,\nthey not only listen, but listen with an almost predatory intensity.\nIs there a hole in the bottom of their boat? Probably not, but if\nthere is, they want to know about it.It's the same with most successful people. They're never more\nengaged than when you disagree with them. Whereas the obstinate\ndon't want to hear you. When you point out problems, their eyes\nglaze over, and their replies sound like ideologues talking about\nmatters of doctrine.\n[2]The reason the persistent and the obstinate seem similar is that\nthey're both hard to stop. But they're hard to stop in different\nsenses. The persistent are like boats whose engines can't be throttled\nback. The obstinate are like boats whose rudders can't be turned.\n[3]In the degenerate case they're indistinguishable: when there's only\none way to solve a problem, your only choice is whether to give up\nor not, and persistence and obstinacy both say no. This is presumably\nwhy the two are so often conflated in popular culture. It assumes\nsimple problems. But as problems get more complicated, we can see\nthe difference between them. The persistent are much more attached\nto points high in the decision tree than to minor ones lower down,\nwhile the obstinate spray \"don't give up\" indiscriminately over the\nwhole tree.The persistent are attached to the goal. The obstinate are attached\nto their ideas about how to reach it.Worse still, that means they'll tend to be attached to their first\nideas about how to solve a problem, even though these are the least\ninformed by the experience of working on it. So the obstinate aren't\nmerely attached to details, but disproportionately likely to be\nattached to wrong ones.Why are they like this? Why are the obstinate obstinate? One\npossibility is that they're overwhelmed. They're not very capable.\nThey take on a hard problem. They're immediately in over their head.\nSo they grab onto ideas the way someone on the deck of a rolling\nship might grab onto the nearest handhold.That was my initial theory, but on examination it doesn't hold up.\nIf being obstinate were simply a consequence of being in over one's\nhead, you could make persistent people become obstinate by making\nthem solve harder problems. But that's not what happens. If you\nhanded the Collisons an extremely hard problem to solve, they\nwouldn't become obstinate. If anything they'd become less obstinate.\nThey'd know they had to be open to anything.Similarly, if obstinacy were caused by the situation, the obstinate\nwould stop being obstinate when solving easier problems. But they\ndon't. And if obstinacy isn't caused by the situation, it must come\nfrom within. It must be a feature of one's personality.Obstinacy is a reflexive resistance to changing one's ideas. This\nis not identical with stupidity, but they're closely related. A\nreflexive resistance to changing one's ideas becomes a sort of\ninduced stupidity as contrary evidence mounts. And obstinacy is a\nform of not giving up that's easily practiced by the stupid. You\ndon't have to consider complicated tradeoffs; you just dig in your\nheels. It even works, up to a point.The fact that obstinacy works for simple problems is an important\nclue. Persistence and obstinacy aren't opposites. The relationship\nbetween them is more like the relationship between the two kinds\nof respiration we can do: aerobic respiration, and the anaerobic\nrespiration we inherited from our most distant ancestors. Anaerobic\nrespiration is a more primitive process, but it has its uses. When\nyou leap suddenly away from a threat, that's what you're using.The optimal amount of obstinacy is not zero. It can be good if your\ninitial reaction to a setback is an unthinking \"I won't give up,\"\nbecause this helps prevent panic. But unthinking only gets you so\nfar. The further someone is toward the obstinate end of the continuum,\nthe less likely they are to succeed in solving hard problems.\n[4]Obstinacy is a simple thing. Animals have it. But persistence turns\nout to have a fairly complicated internal structure.One thing that distinguishes the persistent is their energy. At the\nrisk of putting too much weight on words, they persist rather than\nmerely resisting. They keep trying things. Which means the persistent\nmust also be imaginative. To keep trying things, you have to keep\nthinking of things to try.Energy and imagination make a wonderful combination. Each gets the\nbest out of the other. Energy creates demand for the ideas produced\nby imagination, which thus produces more, and imagination gives\nenergy somewhere to go.\n[5]Merely having energy and imagination is quite rare. But to solve\nhard problems you need three more qualities: resilience, good\njudgement, and a focus on some kind of goal.Resilience means not having one's morale destroyed by setbacks.\nSetbacks are inevitable once problems reach a certain size, so if\nyou can't bounce back from them, you can only do good work on a\nsmall scale. But resilience is not the same as obstinacy. Resilience\nmeans setbacks can't change your morale, not that they can't change\nyour mind.Indeed, persistence often requires that one change one's mind.\nThat's where good judgement comes in. The persistent are quite\nrational. They focus on expected value. It's this, not recklessness,\nthat lets them work on things that are unlikely to succeed.There is one point at which the persistent are often irrational\nthough: at the very top of the decision tree. When they choose\nbetween two problems of roughly equal expected value, the choice\nusually comes down to personal preference. Indeed, they'll often\nclassify projects into deliberately wide bands of expected value\nin order to ensure that the one they want to work on still qualifies.Empirically this doesn't seem to be a problem. It's ok to be\nirrational near the top of the decision tree. One reason is that\nwe humans will work harder on a problem we love. But there's another\nmore subtle factor involved as well: our preferences among problems\naren't random. When we love a problem that other people don't, it's\noften because we've unconsciously noticed that it's more important\nthan they realize.Which leads to our fifth quality: there needs to be some overall\ngoal. If you're like me you began, as a kid, merely with the desire\nto do something great. In theory that should be the most powerful\nmotivator of all, since it includes everything that could possibly\nbe done. But in practice it's not much use, precisely because it\nincludes too much. It doesn't tell you what to do at this moment.So in practice your energy and imagination and resilience and good\njudgement have to be directed toward some fairly specific goal. Not\ntoo specific, or you might miss a great discovery adjacent to what\nyou're searching for, but not too general, or it won't work to\nmotivate you.\n[6]When you look at the internal structure of persistence, it doesn't\nresemble obstinacy at all. It's so much more complex. Five distinct\nqualities — energy, imagination, resilience, good judgement, and\nfocus on a goal — combine to produce a phenomenon that seems a bit\nlike obstinacy in the sense that it causes you not to give up. But\nthe way you don't give up is completely different. Instead of merely\nresisting change, you're driven toward a goal by energy and resilience,\nthrough paths discovered by imagination and optimized by judgement.\nYou'll give way on any point low down in the decision tree, if its\nexpected value drops sufficiently, but energy and resilience keep\npushing you toward whatever you chose higher up.Considering what it's made of, it's not surprising that the right\nkind of stubbornness is so much rarer than the wrong kind, or that\nit gets so much better results. Anyone can do obstinacy. Indeed,\nkids and drunks and fools are best at it. Whereas very few people\nhave enough of all five of the qualities that produce the right kind\nof stubbornness, but when they do the results are magical.\nNotes[1]\nI'm going to use \"persistent\" for the good kind of stubborn\nand \"obstinate\" for the bad kind, but I can't claim I'm simply\nfollowing current usage. Conventional opinion barely distinguishes\nbetween good and bad kinds of stubbornness, and usage is correspondingly\npromiscuous. I could have invented a new word for the good kind,\nbut it seemed better just to stretch \"persistent.\"[2]\nThere are some domains where one can succeed by being obstinate.\nSome political leaders have been notorious for it. But it won't\nwork in situations where you have to pass external tests. And indeed\nthe political leaders who are famous for being obstinate are famous\nfor getting power, not for using it well.[3]\nThere will be some resistance to turning the rudder of a\npersistent person, because there's some cost to changing direction.[4]\nThe obstinate do sometimes succeed in solving hard problems.\nOne way is through luck: like the stopped clock that's right twice\na day, they seize onto some arbitrary idea, and it turns out to be\nright. Another is when their obstinacy cancels out some other form\nof error. For example, if a leader has overcautious subordinates,\ntheir estimates of the probability of success will always be off\nin the same direction. So if he mindlessly says \"push ahead regardless\"\nin every borderline case, he'll usually turn out to be right.[5]\nIf you stop there, at just energy and imagination, you get\nthe conventional caricature of an artist or poet.[6]\nStart by erring on the small side. If you're inexperienced\nyou'll inevitably err on one side or the other, and if you err on\nthe side of making the goal too broad, you won't get anywhere.\nWhereas if you err on the small side you'll at least be moving\nforward. Then, once you're moving, you expand the goal.Thanks to Trevor Blackwell, \nJessica Livingston, Jackie McDonough,\nCourtenay Pipkin, Harj Taggar, and Garry Tan for reading drafts of\nthis."
        ],
        "source_file": null
    },
    {
        "input": "What distinguishes persistent problem-solvers from obstinate ones in tackling intricate challenges efficaciously?",
        "actual_output": null,
        "expected_output": "Persistent problem-solvers differ from obstinate ones by their ability to remain focused on their ultimate goal while being flexible in their approach. They exhibit a combination of energy, imagination, resilience, good judgment, and a strong focus on their objective. They are willing to change their methods based on new insights or setbacks, demonstrating openness to feedback and rational decision-making. Conversely, obstinate individuals tend to adhere rigidly to their initial ideas, resist change, and ignore contrary evidence, which can limit their effectiveness in solving complex problems.",
        "context": [
            "The Right Kind of Stubborn\n\nJuly 2024Successful people tend to be persistent. New ideas often don't work\nat first, but they're not deterred. They keep trying and eventually\nfind something that does.Mere obstinacy, on the other hand, is a recipe for failure. Obstinate\npeople are so annoying. They won't listen. They beat their heads\nagainst a wall and get nowhere.But is there any real difference between these two cases? Are\npersistent and obstinate people actually behaving differently? Or\nare they doing the same thing, and we just label them later as\npersistent or obstinate depending on whether they turned out to be\nright or not?If that's the only difference then there's nothing to be learned\nfrom the distinction. Telling someone to be persistent rather than\nobstinate would just be telling them to be right rather than wrong,\nand they already know that. Whereas if persistence and obstinacy\nare actually different kinds of behavior, it would be worthwhile\nto tease them apart.\n[1]I've talked to a lot of determined people, and it seems to me that\nthey're different kinds of behavior. I've often walked away from a\nconversation thinking either \"Wow, that guy is determined\" or \"Damn,\nthat guy is stubborn,\" and I don't think I'm just talking about\nwhether they seemed right or not. That's part of it, but not all\nof it.There's something annoying about the obstinate that's not simply\ndue to being mistaken. They won't listen. And that's not true of\nall determined people. I can't think of anyone more determined than\nthe Collison brothers, and when you point out a problem to them,\nthey not only listen, but listen with an almost predatory intensity.\nIs there a hole in the bottom of their boat? Probably not, but if\nthere is, they want to know about it.It's the same with most successful people. They're never more\nengaged than when you disagree with them. Whereas the obstinate\ndon't want to hear you. When you point out problems, their eyes\nglaze over, and their replies sound like ideologues talking about\nmatters of doctrine.\n[2]The reason the persistent and the obstinate seem similar is that\nthey're both hard to stop. But they're hard to stop in different\nsenses. The persistent are like boats whose engines can't be throttled\nback. The obstinate are like boats whose rudders can't be turned.\n[3]In the degenerate case they're indistinguishable: when there's only\none way to solve a problem, your only choice is whether to give up\nor not, and persistence and obstinacy both say no. This is presumably\nwhy the two are so often conflated in popular culture. It assumes\nsimple problems. But as problems get more complicated, we can see\nthe difference between them. The persistent are much more attached\nto points high in the decision tree than to minor ones lower down,\nwhile the obstinate spray \"don't give up\" indiscriminately over the\nwhole tree.The persistent are attached to the goal. The obstinate are attached\nto their ideas about how to reach it.Worse still, that means they'll tend to be attached to their first\nideas about how to solve a problem, even though these are the least\ninformed by the experience of working on it. So the obstinate aren't\nmerely attached to details, but disproportionately likely to be\nattached to wrong ones.Why are they like this? Why are the obstinate obstinate? One\npossibility is that they're overwhelmed. They're not very capable.\nThey take on a hard problem. They're immediately in over their head.\nSo they grab onto ideas the way someone on the deck of a rolling\nship might grab onto the nearest handhold.That was my initial theory, but on examination it doesn't hold up.\nIf being obstinate were simply a consequence of being in over one's\nhead, you could make persistent people become obstinate by making\nthem solve harder problems. But that's not what happens. If you\nhanded the Collisons an extremely hard problem to solve, they\nwouldn't become obstinate. If anything they'd become less obstinate.\nThey'd know they had to be open to anything.Similarly, if obstinacy were caused by the situation, the obstinate\nwould stop being obstinate when solving easier problems. But they\ndon't. And if obstinacy isn't caused by the situation, it must come\nfrom within. It must be a feature of one's personality.Obstinacy is a reflexive resistance to changing one's ideas. This\nis not identical with stupidity, but they're closely related. A\nreflexive resistance to changing one's ideas becomes a sort of\ninduced stupidity as contrary evidence mounts. And obstinacy is a\nform of not giving up that's easily practiced by the stupid. You\ndon't have to consider complicated tradeoffs; you just dig in your\nheels. It even works, up to a point.The fact that obstinacy works for simple problems is an important\nclue. Persistence and obstinacy aren't opposites. The relationship\nbetween them is more like the relationship between the two kinds\nof respiration we can do: aerobic respiration, and the anaerobic\nrespiration we inherited from our most distant ancestors. Anaerobic\nrespiration is a more primitive process, but it has its uses. When\nyou leap suddenly away from a threat, that's what you're using.The optimal amount of obstinacy is not zero. It can be good if your\ninitial reaction to a setback is an unthinking \"I won't give up,\"\nbecause this helps prevent panic. But unthinking only gets you so\nfar. The further someone is toward the obstinate end of the continuum,\nthe less likely they are to succeed in solving hard problems.\n[4]Obstinacy is a simple thing. Animals have it. But persistence turns\nout to have a fairly complicated internal structure.One thing that distinguishes the persistent is their energy. At the\nrisk of putting too much weight on words, they persist rather than\nmerely resisting. They keep trying things. Which means the persistent\nmust also be imaginative. To keep trying things, you have to keep\nthinking of things to try.Energy and imagination make a wonderful combination. Each gets the\nbest out of the other. Energy creates demand for the ideas produced\nby imagination, which thus produces more, and imagination gives\nenergy somewhere to go.\n[5]Merely having energy and imagination is quite rare. But to solve\nhard problems you need three more qualities: resilience, good\njudgement, and a focus on some kind of goal.Resilience means not having one's morale destroyed by setbacks.\nSetbacks are inevitable once problems reach a certain size, so if\nyou can't bounce back from them, you can only do good work on a\nsmall scale. But resilience is not the same as obstinacy. Resilience\nmeans setbacks can't change your morale, not that they can't change\nyour mind.Indeed, persistence often requires that one change one's mind.\nThat's where good judgement comes in. The persistent are quite\nrational. They focus on expected value. It's this, not recklessness,\nthat lets them work on things that are unlikely to succeed.There is one point at which the persistent are often irrational\nthough: at the very top of the decision tree. When they choose\nbetween two problems of roughly equal expected value, the choice\nusually comes down to personal preference. Indeed, they'll often\nclassify projects into deliberately wide bands of expected value\nin order to ensure that the one they want to work on still qualifies.Empirically this doesn't seem to be a problem. It's ok to be\nirrational near the top of the decision tree. One reason is that\nwe humans will work harder on a problem we love. But there's another\nmore subtle factor involved as well: our preferences among problems\naren't random. When we love a problem that other people don't, it's\noften because we've unconsciously noticed that it's more important\nthan they realize.Which leads to our fifth quality: there needs to be some overall\ngoal. If you're like me you began, as a kid, merely with the desire\nto do something great. In theory that should be the most powerful\nmotivator of all, since it includes everything that could possibly\nbe done. But in practice it's not much use, precisely because it\nincludes too much. It doesn't tell you what to do at this moment.So in practice your energy and imagination and resilience and good\njudgement have to be directed toward some fairly specific goal. Not\ntoo specific, or you might miss a great discovery adjacent to what\nyou're searching for, but not too general, or it won't work to\nmotivate you.\n[6]When you look at the internal structure of persistence, it doesn't\nresemble obstinacy at all. It's so much more complex. Five distinct\nqualities — energy, imagination, resilience, good judgement, and\nfocus on a goal — combine to produce a phenomenon that seems a bit\nlike obstinacy in the sense that it causes you not to give up. But\nthe way you don't give up is completely different. Instead of merely\nresisting change, you're driven toward a goal by energy and resilience,\nthrough paths discovered by imagination and optimized by judgement.\nYou'll give way on any point low down in the decision tree, if its\nexpected value drops sufficiently, but energy and resilience keep\npushing you toward whatever you chose higher up.Considering what it's made of, it's not surprising that the right\nkind of stubbornness is so much rarer than the wrong kind, or that\nit gets so much better results. Anyone can do obstinacy. Indeed,\nkids and drunks and fools are best at it. Whereas very few people\nhave enough of all five of the qualities that produce the right kind\nof stubbornness, but when they do the results are magical.\nNotes[1]\nI'm going to use \"persistent\" for the good kind of stubborn\nand \"obstinate\" for the bad kind, but I can't claim I'm simply\nfollowing current usage. Conventional opinion barely distinguishes\nbetween good and bad kinds of stubbornness, and usage is correspondingly\npromiscuous. I could have invented a new word for the good kind,\nbut it seemed better just to stretch \"persistent.\"[2]\nThere are some domains where one can succeed by being obstinate.\nSome political leaders have been notorious for it. But it won't\nwork in situations where you have to pass external tests. And indeed\nthe political leaders who are famous for being obstinate are famous\nfor getting power, not for using it well.[3]\nThere will be some resistance to turning the rudder of a\npersistent person, because there's some cost to changing direction.[4]\nThe obstinate do sometimes succeed in solving hard problems.\nOne way is through luck: like the stopped clock that's right twice\na day, they seize onto some arbitrary idea, and it turns out to be\nright. Another is when their obstinacy cancels out some other form\nof error. For example, if a leader has overcautious subordinates,\ntheir estimates of the probability of success will always be off\nin the same direction. So if he mindlessly says \"push ahead regardless\"\nin every borderline case, he'll usually turn out to be right.[5]\nIf you stop there, at just energy and imagination, you get\nthe conventional caricature of an artist or poet.[6]\nStart by erring on the small side. If you're inexperienced\nyou'll inevitably err on one side or the other, and if you err on\nthe side of making the goal too broad, you won't get anywhere.\nWhereas if you err on the small side you'll at least be moving\nforward. Then, once you're moving, you expand the goal.Thanks to Trevor Blackwell, \nJessica Livingston, Jackie McDonough,\nCourtenay Pipkin, Harj Taggar, and Garry Tan for reading drafts of\nthis."
        ],
        "source_file": null
    },
    {
        "input": "How did wokeness originate in the late 1980s, influenced by political correctness?",
        "actual_output": null,
        "expected_output": "Wokeness originated in the late 1980s as a more aggressive form of political correctness, which itself is defined as an aggressively performative focus on social justice. The origins trace back to the humanities and social sciences within universities, where 1960s radicals who became professors injected their political beliefs into academia. These fields offered more scope for such political influence, unlike the hard sciences. As the previous generation of professors retired, these radicals gained power, enforcing new moral rules focused on issues like sexism and racism. This shifted the focus from protest movements to formal complaints about inappropriate behavior, transforming what was once student-driven protest into a faculty-endorsed enforcement of social justice norms.",
        "context": [
            "The Origins of Wokeness\n\nJanuary 2025The word \"prig\" isn't very common now, but if you look up\nthe definition, it will sound familiar. Google's isn't bad:\n\n  A self-righteously moralistic person who behaves as if\n  superior to others.\n\nThis sense of the word originated in the 18th century, and\nits age is an important clue: it shows that although\nwokeness is a comparatively recent phenomenon, it's an\ninstance of a much older one.There's a certain kind of person who's attracted to a\nshallow, exacting kind of moral purity, and who demonstrates\nhis purity by attacking anyone who breaks the rules. Every\nsociety has these people. All that changes is the rules they\nenforce. In Victorian England it was Christian virtue. In\nStalin's Russia it was orthodox Marxism-Leninism. For the\nwoke, it's social justice.So if you want to understand wokeness, the question to ask\nis not why people behave this way. Every society has prigs.\nThe question to ask is why our prigs are priggish about\nthese ideas, at this moment. And to answer that we have to\nask when and where wokeness began.The answer to the first question is the 1980s. Wokeness is a\nsecond, more aggressive wave of political correctness, which\nstarted in the late 1980s, died down in the late 1990s, and\nthen returned with a vengeance in the early 2010s, finally\npeaking after the riots of 2020.What was political correctness, exactly? I'm often asked to define\nboth this term and wokeness by people who think they're meaningless\nlabels, so I will. They both have the same definition:\n\n  An aggressively performative focus on social justice.\n\nIn other words, it's people being prigs about social\njustice. And that's the real problem — the\nperformativeness, not the social justice.\n[0]Racism, for example, is a genuine problem. Not a problem on\nthe scale that the woke believe it to be, but a genuine one.\nI don't think any reasonable person would deny that. The\nproblem with political correctness was not that it focused\non marginalized groups, but the shallow, aggressive way in\nwhich it did so. Instead of going out into the world and\nquietly helping members of marginalized groups, the\npolitically correct focused on getting people in trouble for\nusing the wrong words to talk about them.As for where political correctness began, if you think about\nit, you probably already know the answer. Did it begin\noutside universities and spread to them from this external\nsource? Obviously not; it has always been most extreme in\nuniversities. So where in universities did it begin? Did it\nbegin in math, or the hard sciences, or engineering, and\nspread from there to the humanities and social sciences?\nThose are amusing images, but no, obviously it began in the\nhumanities and social sciences.Why there? And why then? What happened in the humanities and\nsocial sciences in the 1980s?A successful theory of the origin of political correctness\nhas to be able to explain why it didn't happen earlier. Why\ndidn't it happen during the protest movements of the 1960s,\nfor example? They were concerned with much the same issues.\n[1]The reason the student protests of the 1960s didn't lead to\npolitical correctness was precisely that — they were\nstudent movements. They didn't have any real power. The\nstudents may have been talking a lot about women's\nliberation and black power, but it was not what they were\nbeing taught in their classes. Not yet.But in the early 1970s the student protestors of the 1960s\nbegan to finish their dissertations and get hired as\nprofessors. At first they were neither powerful nor\nnumerous. But as more of their peers joined them and the\nprevious generation of professors started to retire, they\ngradually became both.The reason political correctness began in the humanities and\nsocial sciences was that these fields offered more scope for\nthe injection of politics. A 1960s radical who got a job as\na physics professor could still attend protests, but his\npolitical beliefs wouldn't affect his work. Whereas research\nin sociology and modern literature can be made as political\nas you like.\n[2]I saw political correctness arise. When I started college in\n1982 it was not yet a thing. Female students might object if\nsomeone said something they considered sexist, but no one\nwas getting reported for it. It was still not a thing when\nI started grad school in 1986. It was definitely a thing in\n1988 though, and by the early 1990s it seemed to pervade\ncampus life.What happened? How did protest become punishment? Why were\nthe late 1980s the point at which protests against male\nchauvinism (as it used to be called) morphed into formal\ncomplaints to university authorities about sexism?\nBasically, the 1960s radicals got tenure. They became the\nEstablishment they'd protested against two decades before.\nNow they were in a position not just to speak out about\ntheir ideas, but to enforce them.A new set of moral rules to enforce was exciting news to a\ncertain kind of student. What made it particularly exciting\nwas that they were allowed to attack professors. I remember\nnoticing that aspect of political correctness at the time.\nIt wasn't simply a grass-roots student movement. It was\nfaculty members encouraging students to attack other faculty\nmembers. In that respect it was like the Cultural\nRevolution. That wasn't a grass-roots movement either; that\nwas Mao unleashing the younger generation on his political\nopponents. And in fact when Roderick MacFarquhar started\nteaching a class on the Cultural Revolution at Harvard in\nthe late 1980s, many saw it as a comment on current events.\nI don't know if it actually was, but people thought it was,\nand that means the similarities were obvious.\n[3]College students larp. It's their nature. It's usually\nharmless. But larping morality turned out to be a poisonous\ncombination. The result was a kind of moral etiquette,\nsuperficial but very complicated. Imagine having to explain\nto a well-meaning visitor from another planet why using the\nphrase \"people of color\" is considered particularly\nenlightened, but saying \"colored people\" gets you fired. And\nwhy exactly one isn't supposed to use the word \"negro\" now,\neven though Martin Luther King used it constantly in his\nspeeches. There are no underlying principles. You'd just\nhave to give him a long list of rules to memorize.\n[4]\nThe danger of these rules was not just that they created\nland mines for the unwary, but that their elaborateness made\nthem an effective substitute for virtue. Whenever a society\nhas a concept of heresy and orthodoxy, orthodoxy becomes a\nsubstitute for virtue. You can be the worst person in the\nworld, but as long as you're orthodox you're better than\neveryone who isn't. This makes orthodoxy very attractive to\nbad people.But for it to work as a substitute for virtue, orthodoxy\nmust be difficult. If all you have to do to be orthodox is\nwear some garment or avoid saying some word, everyone knows\nto do it, and the only way to seem more virtuous than other\npeople is to actually be virtuous. The shallow, complicated,\nand frequently changing rules of political correctness made\nit the perfect substitute for actual virtue. And the result\nwas a world in which good people who weren't up to date on\ncurrent moral fashions were brought down by people whose\ncharacters would make you recoil in horror if you could see\nthem.One big contributing factor in the rise of political\ncorrectness was the lack of other things to be morally pure\nabout. Previous generations of prigs had been prigs mostly\nabout religion and sex. But among the cultural elite these\nwere the deadest of dead letters by the 1980s; if you were\nreligious, or a virgin, this was something you tended to\nconceal rather than advertise. So the sort of people who\nenjoy being moral enforcers had become starved of things to\nenforce. A new set of rules was just what they'd been\nwaiting for.Curiously enough, the tolerant side of the 1960s left helped\ncreate the conditions in which the intolerant side\nprevailed. The relaxed social rules advocated by the old,\neasy-going hippy left became the dominant ones, at least\namong the elite, and this left nothing for the naturally\nintolerant to be intolerant about.Another possibly contributing factor was the fall of the\nSoviet empire. Marxism had been a popular focus of moral\npurity on the left before political correctness emerged as a\ncompetitor, but the pro-democracy movements in Eastern Bloc\ncountries took most of the shine off it. Especially the fall\nof the Berlin Wall in 1989. You couldn't be on the side of\nthe Stasi. I remember looking at the moribund Soviet Studies\nsection of a used bookshop in Cambridge in the late 1980s\nand thinking \"what will those people go on about now?\" As it\nturned out the answer was right under my nose.One thing I noticed at the time about the first phase of\npolitical correctness was that it was more popular with\nwomen than men. As many writers (perhaps most eloquently\nGeorge Orwell) have observed, women seem more attracted than\nmen to the idea of being moral enforcers. But there was\nanother more specific reason women tended to be the\nenforcers of political correctness. There was at this time a\ngreat backlash against sexual harassment; the mid 1980s were\nthe point when the definition of sexual harassment was\nexpanded from explicit sexual advances to creating a\n\"hostile environment.\" Within universities the classic form\nof accusation was for a (female) student to say that a\nprofessor made her \"feel uncomfortable.\" But the vagueness\nof this accusation allowed the radius of forbidden behavior\nto expand to include talking about heterodox ideas. Those\nmake people uncomfortable too.\n[5]Was it sexist to propose that Darwin's greater male\nvariability hypothesis might explain some variation in human\nperformance? Sexist enough to get Larry Summers pushed out\nas president of Harvard, apparently. One woman who heard the\ntalk in which he mentioned this idea said it made her feel\n\"physically ill\" and that she had to leave halfway through.\nIf the test of a hostile environment is how it makes people\nfeel, this certainly sounds like one. And yet it does seem\nplausible that greater male variability explains some of the\nvariation in human performance. So which should prevail,\ncomfort or truth? Surely if truth should prevail anywhere,\nit should be in universities; that's supposed to be their\nspecialty; but for decades starting in the late 1980s the\npolitically correct tried to pretend this conflict didn't\nexist.\n[6]Political correctness seemed to burn out in the second half\nof the 1990s. One reason, perhaps the main reason, was that\nit literally became a joke. It offered rich material for\ncomedians, who performed their usual disinfectant action\nupon it. Humor is one of the most powerful weapons against\npriggishness of any sort, because prigs, being humorless,\ncan't respond in kind. Humor was what defeated Victorian\nprudishness, and by 2000 it seemed to have done the same\nthing to political correctness.Unfortunately this was an illusion. Within universities the\nembers of political correctness were still glowing brightly.\nAfter all, the forces that created it were still there. The\nprofessors who started it were now becoming deans and\ndepartment heads. And in addition to their departments there\nwere now a bunch of new ones explicitly focused on social\njustice. Students were still hungry for things to be morally\npure about. And there had been an explosion in the number of\nuniversity administrators, many of whose jobs involved\nenforcing various forms of political correctness.In the early 2010s the embers of political correctness burst\ninto flame anew. There were several differences between this\nnew phase and the original one. It was more virulent. It\nspread further into the real world, although it still burned\nhottest within universities. And it was concerned with a\nwider variety of sins. In the first phase of political\ncorrectness there were really only three things people got\naccused of: sexism, racism, and homophobia (which at the\ntime was a neologism invented for the purpose). But between\nthen and 2010 a lot of people had spent a lot of time trying\nto invent new kinds of -isms and -phobias and seeing which\ncould be made to stick.The second phase was, in multiple senses, political\ncorrectness metastasized. Why did it happen when it did? My\nguess is that it was due to the rise of social media,\nparticularly Tumblr and Twitter, because one of the most\ndistinctive features of the second wave of political\ncorrectness was the cancel mob: a mob of angry people\nuniting on social media to get someone ostracized or fired.\nIndeed this second wave of political correctness was\noriginally called \"cancel culture\"; it didn't start to be\ncalled \"wokeness\" till the 2020s.One aspect of social media that surprised almost everyone at\nfirst was the popularity of outrage. Users seemed to like\nbeing outraged. We're so used to this idea now that we take\nit for granted, but really it's pretty strange. Being\noutraged is not a pleasant feeling. You wouldn't expect\npeople to seek it out. But they do. And above all, they want\nto share it. I happened to be running a forum from 2007 to\n2014, so I can actually quantify how much they want to share\nit: our users were about three times more likely to upvote\nsomething if it outraged them.This tilt toward outrage wasn't due to wokeness. It's an\ninherent feature of social media, or at least this\ngeneration of it. But it did make social media the perfect\nmechanism for fanning the flames of wokeness.\n[7]It wasn't just public social networks that drove the rise of\nwokeness though. Group chat apps were also critical,\nespecially in the final step, cancellation. Imagine if a\ngroup of employees trying to get someone fired had to do it\nusing only email. It would be hard to organize a mob. But\nonce you have group chat, mobs form naturally.Another contributing factor in this second wave of political\ncorrectness was the dramatic increase in the polarization of\nthe press. In the print era, newspapers were constrained to\nbe, or at least seem, politically neutral. The department\nstores that ran ads in the New York Times wanted to reach\neveryone in the region, both liberal and conservative, so\nthe Times had to serve both. But the Times didn't regard\nthis neutrality as something forced upon them. They embraced\nit as their duty as a paper of record — as one of the big\nnewspapers that aimed to be chronicles of their times,\nreporting every sufficiently important story from a neutral\npoint of view.When I grew up the papers of record seemed timeless, almost\nsacred institutions. Papers like the New York Times and\nWashington Post had immense prestige, partly because other\nsources of news were limited, but also because they did make\nsome effort to be neutral.Unfortunately it turned out that the paper of record was\nmostly an artifact of the constraints imposed by print.\n[8]\nWhen your market was determined by geography, you had\nto be neutral. But publishing online enabled — in fact\nprobably forced — newspapers to switch to serving markets\ndefined by ideology instead of geography. Most that remained\nin business fell in the direction they'd already been\nleaning: left. On October 11, 2020 the New York Times\nannounced that \"The paper is in the midst of an evolution\nfrom the stodgy paper of record into a juicy collection of\ngreat narratives.\"\n[9]\nMeanwhile journalists, of a sort,\nhad arisen to serve the right as well. And so journalism,\nwhich in the previous era had been one of the great\ncentralizing forces, now became one of the great polarizing\nones.The rise of social media and the increasing polarization of\njournalism reinforced one another. In fact there arose a new\nvariety of journalism involving a loop through social media.\nSomeone would say something controversial on social media.\nWithin hours it would become a news story. Outraged readers\nwould then post links to the story on social media, driving\nfurther arguments online. It was the cheapest source of\nclicks imaginable. You didn't have to maintain overseas news\nbureaus or pay for month-long investigations. All you had to\ndo was watch Twitter for controversial remarks and repost\nthem on your site, with some additional comments to inflame\nreaders further.For the press there was money in wokeness. But they weren't\nthe only ones. That was one of the biggest differences\nbetween the two waves of political correctness: the first\nwas driven almost entirely by amateurs, but the second was\noften driven by professionals. For some it was their whole\njob. By 2010 a new class of administrators had arisen whose\njob was basically to enforce wokeness. They played a role\nsimilar to that of the political commissars who got attached\nto military and industrial organizations in the USSR: they\nweren't directly in the flow of the organization's work, but\nwatched from the side to ensure that nothing improper\nhappened in the doing of it. These new administrators could\noften be recognized by the word \"inclusion\" in their titles.\nWithin institutions this was the preferred euphemism for\nwokeness; a new list of banned words, for example, would\nusually be called an \"inclusive language guide.\"\n[10]This new class of bureaucrats pursued a woke agenda as if\ntheir jobs depended on it, because they did. If you hire\npeople to keep watch for a particular type of problem,\nthey're going to find it, because otherwise there's no\njustification for their existence.\n[11]\nBut these\nbureaucrats also represented a second and possibly even\ngreater danger. Many were involved in hiring, and when\npossible they tried to ensure their employers hired only\npeople who shared their political beliefs. The most\negregious cases were the new \"DEI statements\" that some\nuniversities started to require from faculty candidates,\nproving their commitment to wokeness. Some universities used\nthese statements as the initial filter and only even\nconsidered candidates who scored high enough on them. You're\nnot hiring Einstein that way; imagine what you get instead.Another factor in the rise of wokeness was the Black Lives\nMatter movement, which started in 2013 when a white man was\nacquitted after killing a black teenager in Florida. But\nthis didn't launch wokeness; it was well underway by 2013.Similarly for the Me Too Movement, which took off in 2017\nafter the first news stories about Harvey Weinstein's\nhistory of raping women. It accelerated wokeness, but didn't\nplay the same role in launching it that the 80s version did\nin launching political correctness.The election of Donald Trump in 2016 also accelerated\nwokeness, particularly in the press, where outrage now meant\ntraffic. Trump made the New York Times a lot of money:\nheadlines during his first administration mentioned his name\nat about four times the rate of previous presidents.In 2020 we saw the biggest accelerant of all, after a white\npolice officer asphyxiated a black suspect on video. At this\npoint the metaphorical fire became a literal one, as violent\nprotests broke out across America. But in retrospect this\nturned out to be peak woke, or close to it. By every measure\nI've seen, wokeness peaked in 2020 or 2021.Wokeness is sometimes described as a mind-virus. What makes\nit viral is that it defines new types of impropriety. Most\npeople are afraid of impropriety; they're never exactly sure\nwhat the social rules are or which ones they might be\nbreaking. Especially if the rules change rapidly. And since\nmost people already worry that they might be breaking rules\nthey don't know about, if you tell them they're breaking a\nrule, their default reaction is to believe you. Especially\nif multiple people tell them. Which in turn is a recipe for\nexponential growth. Zealots invent some new impropriety to\navoid. The first people to adopt it are fellow zealots,\neager for new ways to signal their virtue. If there are\nenough of these, the initial group of zealots is followed by\na much larger group, motivated by fear. They're not trying\nto signal virtue; they're just trying to avoid getting in\ntrouble. At this point the new impropriety is now firmly\nestablished. Plus its success has increased the rate of\nchange in social rules, which, remember, is one of the\nreasons people are nervous about which rules they might be\nbreaking. So the cycle accelerates.\n[12]What's true of individuals is even more true of\norganizations. Especially organizations without a powerful\nleader. Such organizations do everything based on \"best\npractices.\" There's no higher authority; if some new \"best\npractice\" achieves critical mass, they must adopt it. And\nin this case the organization can't do what it usually does\nwhen it's uncertain: delay. It might be committing\nimproprieties right now! So it's surprisingly easy for a\nsmall group of zealots to capture this type of organization\nby describing new improprieties it might be guilty of. \n[13]How does this kind of cycle ever end? Eventually it leads to\ndisaster, and people start to say enough is enough. The\nexcesses of 2020 made a lot of people say that.Since then wokeness has been in gradual but continual\nretreat. Corporate CEOs, starting with Brian Armstrong, have\nopenly rejected it. Universities, led by the University of\nChicago and MIT, have explicitly confirmed their commitment\nto free speech. Twitter, which was arguably the hub of\nwokeness, was bought by Elon Musk in order to neutralize it,\nand he seems to have succeeded — and not, incidentally, by\ncensoring left-wing users the way Twitter used to censor\nright-wing ones, but without censoring either.\n[14]\nConsumers have emphatically rejected brands that ventured\ntoo far into wokeness. The Bud Light brand may have been\npermanently damaged by it. I'm not going to claim Trump's\nsecond victory in 2024 was a referendum on wokeness; I think\nhe won, as presidential candidates always do, because he was\nmore charismatic; but voters' \ndisgust with wokeness must have helped.So what do we do now? Wokeness is already in retreat.\nObviously we should help it along. What's the best way to do\nthat? And more importantly, how do we avoid a third\noutbreak? After all, it seemed to be dead once, but came\nback worse than ever.In fact there's an even more ambitious goal: is there a way\nto prevent any similar outbreak of aggressively performative\nmoralism in the future — not just a third outbreak of\npolitical correctness, but the next thing like it? Because\nthere will be a next thing. Prigs are prigs by nature. They\nneed rules to obey and enforce, and now that Darwin has cut\noff their traditional supply of rules, they're constantly\nhungry for new ones. All they need is someone to meet them\nhalfway by defining a new way to be morally pure, and we'll\nsee the same phenomenon again.Let's start with the easier problem. Is there a simple,\nprincipled way to deal with wokeness? I think there is: to\nuse the customs we already have for dealing with religion.\nWokeness is effectively a religion, just with God replaced\nby protected classes. It's not even the first religion of\nthis kind; Marxism had a similar form, with God replaced by\nthe masses.\n[15]\nAnd we already have well-established\ncustoms for dealing with religion within organizations. You\ncan express your own religious identity and explain your\nbeliefs, but you can't call your coworkers infidels if they\ndisagree, or try to ban them from saying things that\ncontradict its doctrines, or insist that the organization\nadopt yours as its official religion.If we're not sure what to do about any particular\nmanifestation of wokeness, imagine we were dealing with some\nother religion, like Christianity. Should we have people\nwithin organizations whose jobs are to enforce woke\northodoxy? No, because we wouldn't have people whose jobs\nwere to enforce Christian orthodoxy. Should we censor\nwriters or \nscientists whose work contradicts woke doctrines?\nNo, because we wouldn't do this to people whose work\ncontradicted Christian teachings. Should job candidates be\nrequired to write DEI statements? Of course not; imagine an\nemployer requiring proof of one's religious beliefs. Should\nstudents and employees have to participate in woke\nindoctrination sessions in which they're required to answer\nquestions about their beliefs to ensure compliance? No,\nbecause we wouldn't dream of catechizing people in this way\nabout their religion.\n[16]One shouldn't feel bad about not wanting to watch woke\nmovies any more than one would feel bad about not wanting to\nlisten to Christian rock. In my twenties I drove across\nAmerica several times, listening to local radio stations.\nOccasionally I'd turn the dial and hear some new song. But\nthe moment anyone mentioned Jesus I'd turn the dial again.\nEven the tiniest bit of being preached to was enough to make\nme lose interest.But by the same token we should not automatically reject\neverything the woke believe. I'm not a Christian, but I can\nsee that many Christian principles are good ones. It would\nbe a mistake to discard them all just because one didn't\nshare the religion that espoused them. It would be the sort\nof thing a religious zealot would do.If we have genuine pluralism, I think we'll be safe from\nfuture outbreaks of woke intolerance. Wokeness itself won't\ngo away. There will for the foreseeable future continue to\nbe pockets of woke zealots inventing new moral fashions. The\nkey is not to let them treat their fashions as normative.\nThey can change what their coreligionists are allowed to say\nevery few months if they like, but they mustn't be allowed\nto change what we're allowed to say.\n[17]The more general problem — how to prevent similar outbreaks\nof aggressively performative moralism — is of course\nharder. Here we're up against human nature. There will\nalways be prigs. And in particular there will always be the\nenforcers among them, the \naggressively conventional-minded.\nThese people are born that way. Every society has them. So\nthe best we can do is to keep them bottled up.The aggressively conventional-minded aren't always on the\nrampage. Usually they just enforce whatever random rules are\nnearest to hand. They only become dangerous when some new\nideology gets a lot of them pointed in the same direction at\nonce. That's what happened during the Cultural Revolution,\nand to a lesser extent (thank God) in the two waves of\npolitical correctness we've experienced.We can't get rid of the aggressively conventional-minded.\n[18]\nAnd we couldn't prevent people from creating new\nideologies that appealed to them even if we wanted to. So if\nwe want to keep them bottled up, we have to do it one step\ndownstream. Fortunately when the aggressively\nconventional-minded go on the rampage they always do one\nthing that gives them away: they define new heresies to\npunish people for. So the best way to protect ourselves from\nfuture outbreaks of things like wokeness is to have powerful\nantibodies against the concept of heresy.We should have a conscious bias against defining new forms\nof heresy. Whenever anyone tries to ban saying something\nthat we'd previously been able to say, our initial\nassumption should be that they're wrong. Only our initial\nassumption of course. If they can prove we should stop\nsaying it, then we should. But the burden of proof is on\nthem. In liberal democracies, people trying to prevent\nsomething from being said will usually claim they're not\nmerely engaging in censorship, but trying to prevent some\nform of \"harm\". And maybe they're right. But once again, the\nburden of proof is on them. It's not enough to claim harm;\nthey have to prove it.As long as the aggressively conventional-minded continue to\ngive themselves away by banning heresies, we'll always be\nable to notice when they become aligned behind some new\nideology. And if we always fight back at that point, with\nany luck we can stop them in their tracks.The number of true things we can't say\nshould not increase. If it does, something is wrong.Notes[0]\nThis was not the original meaning of \"woke,\" but it's rarely\nused in the original sense now. Now the pejorative sense is\nthe dominant one.[1]\nWhy did 1960s radicals focus on the causes they did?\nOne of the people who reviewed drafts of this essay\nexplained this so well that I asked if I could quote him:\n\n  The middle-class student protestors of the New Left\n  rejected the socialist/Marxist left as unhip. They were\n  interested in sexier forms of oppression uncovered by\n  cultural analysis (Marcuse) and abstruse \"Theory\". Labor\n  politics became stodgy and old-fashioned. This took a\n  couple generations to work through. The woke ideology's\n  conspicuous lack of interest in the working class is the\n  tell-tale sign. Such fragments as are, er, left of the old\n  left are anti-woke, and meanwhile the actual working class\n  shifted to the populist right and gave us Trump. Trump and\n  wokeness are cousins.The middle-class origins of wokeness smoothed its way\n  through the institutions because it had no interest in\n  \"seizing the means of production\" (how quaint such phrases\n  seem now), which would quickly have run up against hard\n  state and corporate power. The fact that wokeness only\n  expressed interest in other kinds of class (race, sex,\n  etc) signalled compromise with existing power: give us\n  power within your system and we'll bestow the resource we\n  control — moral rectitude — upon you. As an ideological\n  stalking horse for gaining control over discourse and\n  institutions, this succeeded where a more ambitious\n  revolutionary program would not have.\n\n[2]\nIt helped that the humanities and social sciences also\nincluded some of the biggest and easiest undergrad majors.\nIf a political movement had to start with physics students,\nit could never get off the ground; there would be too few of\nthem, and they wouldn't have the time to spare.At the top universities these majors are not as big as they\nused to be, though. A \n2022 survey found that only 7% of\nHarvard undergrads plan to major in the humanities, vs\nnearly 30% during the 1970s. I expect wokeness is at least\npart of the reason; when undergrads consider majoring in\nEnglish, it's presumably because they love the written word\nand not because they want to listen to lectures about\nracism.[3]\nThe puppet-master-and-puppet character of political\ncorrectness became clearly visible when a bakery near\nOberlin College was falsely accused of race discrimination\nin 2016. In the subsequent civil trial, lawyers for the\nbakery produced a text message from Oberlin Dean of Students\nMeredith Raimondo that read \"I'd say unleash the students if\nI wasn't convinced this needs to be put behind us.\"[4]\nThe woke sometimes claim that wokeness is simply\ntreating people with respect. But if it were, that would be\nthe only rule you'd have to remember, and this is comically\nfar from being the case. My younger son likes to imitate\nvoices, and at one point when he was about seven I had to\nexplain which accents it was currently safe to imitate\npublicly and which not. It took about ten minutes, and I\nstill hadn't covered all the cases.[5]\nIn 1986 the Supreme Court ruled that creating a\nhostile work environment could constitute sex\ndiscrimination, which in turn affected universities via\nTitle IX. The court specified that the test of a hostile\nenvironment was whether it would bother a reasonable person,\nbut since for a professor merely being the subject of a\nsexual harassment complaint would be a disaster whether the\ncomplainant was reasonable or not, in practice any joke or\nremark remotely connected with sex was now effectively\nforbidden. Which meant we'd now come full circle to\nVictorian codes of behavior, when there was a large class of\nthings that might not be said \"with ladies present.\"[6]\nMuch as they tried to pretend there was no conflict\nbetween diversity and quality. But you can't simultaneously\noptimize for two things that aren't identical. What\ndiversity actually means, judging from the way the term is\nused, is proportional representation, and unless you're\nselecting a group whose purpose is to be representative,\nlike poll respondents, optimizing for proportional\nrepresentation has to come at the expense of quality. This\nis not because of anything about representation; it's the\nnature of optimization; optimizing for x has to come at the\nexpense of y unless x and y are identical.[7]\nMaybe societies will eventually develop antibodies to\nviral outrage. Maybe we were just the first to be exposed to\nit, so it tore through us like an epidemic through a\npreviously isolated population. I'm fairly confident that it\nwould be possible to create new social media apps that were\nless driven by outrage, and an app of this type would have a\ngood chance of stealing users from existing ones, because\nthe smartest people would tend to migrate to it.[8]\nI say \"mostly\" because I have hopes that journalistic\nneutrality will return in some form. There is some market\nfor unbiased news, and while it may be small, it's valuable.\nThe rich and powerful want to know what's really going on;\nthat's how they became rich and powerful.[9]\nThe Times made this momentous announcement very\ninformally, in passing in the middle of an \narticle about a\nTimes reporter who'd been criticized for inaccuracy. It's\nquite possible no senior editor even approved it. But it's\nsomehow appropriate that this particular universe ended with\na whimper rather than a bang.[10]\nAs the acronym DEI goes out of fashion, many of these\nbureaucrats will try to go underground by changing their\ntitles. It looks like \"belonging\" will be a popular option.[11]\nIf you've ever wondered why our legal system includes\nprotections like the separation of prosecutor, judge, and\njury, the right to examine evidence and cross-examine\nwitnesses, and the right to be represented by legal counsel,\nthe de facto \nparallel legal system\nestablished by Title IX\nmakes that all too clear.[12]\nThe invention of new improprieties is most visible in\nthe rapid evolution of woke nomenclature. This is\nparticularly annoying to me as a writer, because the new\nnames are always worse. Any religious observance has to be\ninconvenient and slightly absurd; otherwise gentiles would\ndo it too. So \"slaves\" becomes \"enslaved individuals.\" But\nweb search can show us the leading edge of moral growth in\nreal time: if you search for \"individuals experiencing\nslavery\" you will as of this writing find five legit\nattempts to use the phrase, and you'll even find two for\n\"individuals experiencing enslavement.\"[13]\nOrganizations that do dubious things are particularly\nconcerned with propriety, which is how you end up with\nabsurdities like tobacco and oil companies having higher ESG\nratings than Tesla.[14]\nElon did something else that tilted Twitter rightward\nthough: he gave more visibility to paying users. Paying\nusers lean right on average, because people on the far left\ndislike Elon and don't want to give him money. Elon\npresumably knew this would happen. On the other hand, the\npeople on the far left have only themselves to blame; they\ncould tilt Twitter back to the left tomorrow if they wanted\nto.[15]\nIt even, as James Lindsay and Peter Boghossian\npointed out, has a concept of original sin: privilege. Which\nmeans unlike Christianity's egalitarian version, people have varying\ndegrees of it. An able-bodied straight white\nAmerican male is born with such a load of sin that only by\nthe most abject repentance can he be saved.Wokeness also shares something rather funny with many actual\nversions of Christianity: like God, the people for whose\nsake wokeness purports to act are often revolted by the\nthings done in their name.[16]\nThere is one exception to most of these rules: actual\nreligious organizations. It's reasonable for them to insist\non orthodoxy. But they in turn should declare that they're\nreligious organizations. It's rightly considered shady\nwhen something that appears to be an ordinary business or\npublication turns out to be a religious organization.[17]\nI don't want to give the impression that it will be\nsimple to roll back wokeness. There will be places where the\nfight inevitably gets messy — particularly within\nuniversities, which everyone has to share, yet which are\ncurrently the most pervaded by wokeness of any institutions.[18]\nYou can however get rid of aggressively\nconventional-minded people within an organization, and in\nmany if not most organizations this would be an excellent\nidea. Even a handful of them can do a lot of damage. I bet\nyou'd feel a noticeable improvement going from a handful to\nnone.Thanks to Sam Altman, \nBen Miller, Daniel Gackle, Robin Hanson, Jessica\nLivingston, Greg Lukianoff, Harj Taggar, Garry Tan, and Tim\nUrban for reading drafts of this."
        ],
        "source_file": null
    },
    {
        "input": "How do wokeness and historical moral enforcement practices compare in terms of origins and characteristics?",
        "actual_output": null,
        "expected_output": "Wokeness and historical moral enforcement practices, such as Victorian prudishness and Marxist orthodoxy, share similarities in origins and characteristics. Both involve a group of people attracted to enforcing a form of moral purity and attack those breaking the established rules. While the specifics of the rules change over time, the underlying behavior remains constant.\n\nThe phenomenon of wokeness is a modern instance of this age-old behavior. Its origins trace back to the 1980s as a more aggressive wave of what was known as political correctness. This movement began in the humanities and social sciences within universities, where politics could easily be injected into academic discourse. It transformed into a broader societal phenomenon, peaking in influence around 2020. The characteristic of performative focus on social justice is similar to past moral enforcement, focusing on outward adherence to a complex and ever-changing set of rules.\n\nIn essence, wokeness is a contemporary iteration of historical priggishness, with social justice as its focal point, akin to religious or ideological orthodoxy that characterized past enforcement practices.",
        "context": [
            "The Origins of Wokeness\n\nJanuary 2025The word \"prig\" isn't very common now, but if you look up\nthe definition, it will sound familiar. Google's isn't bad:\n\n  A self-righteously moralistic person who behaves as if\n  superior to others.\n\nThis sense of the word originated in the 18th century, and\nits age is an important clue: it shows that although\nwokeness is a comparatively recent phenomenon, it's an\ninstance of a much older one.There's a certain kind of person who's attracted to a\nshallow, exacting kind of moral purity, and who demonstrates\nhis purity by attacking anyone who breaks the rules. Every\nsociety has these people. All that changes is the rules they\nenforce. In Victorian England it was Christian virtue. In\nStalin's Russia it was orthodox Marxism-Leninism. For the\nwoke, it's social justice.So if you want to understand wokeness, the question to ask\nis not why people behave this way. Every society has prigs.\nThe question to ask is why our prigs are priggish about\nthese ideas, at this moment. And to answer that we have to\nask when and where wokeness began.The answer to the first question is the 1980s. Wokeness is a\nsecond, more aggressive wave of political correctness, which\nstarted in the late 1980s, died down in the late 1990s, and\nthen returned with a vengeance in the early 2010s, finally\npeaking after the riots of 2020.What was political correctness, exactly? I'm often asked to define\nboth this term and wokeness by people who think they're meaningless\nlabels, so I will. They both have the same definition:\n\n  An aggressively performative focus on social justice.\n\nIn other words, it's people being prigs about social\njustice. And that's the real problem — the\nperformativeness, not the social justice.\n[0]Racism, for example, is a genuine problem. Not a problem on\nthe scale that the woke believe it to be, but a genuine one.\nI don't think any reasonable person would deny that. The\nproblem with political correctness was not that it focused\non marginalized groups, but the shallow, aggressive way in\nwhich it did so. Instead of going out into the world and\nquietly helping members of marginalized groups, the\npolitically correct focused on getting people in trouble for\nusing the wrong words to talk about them.As for where political correctness began, if you think about\nit, you probably already know the answer. Did it begin\noutside universities and spread to them from this external\nsource? Obviously not; it has always been most extreme in\nuniversities. So where in universities did it begin? Did it\nbegin in math, or the hard sciences, or engineering, and\nspread from there to the humanities and social sciences?\nThose are amusing images, but no, obviously it began in the\nhumanities and social sciences.Why there? And why then? What happened in the humanities and\nsocial sciences in the 1980s?A successful theory of the origin of political correctness\nhas to be able to explain why it didn't happen earlier. Why\ndidn't it happen during the protest movements of the 1960s,\nfor example? They were concerned with much the same issues.\n[1]The reason the student protests of the 1960s didn't lead to\npolitical correctness was precisely that — they were\nstudent movements. They didn't have any real power. The\nstudents may have been talking a lot about women's\nliberation and black power, but it was not what they were\nbeing taught in their classes. Not yet.But in the early 1970s the student protestors of the 1960s\nbegan to finish their dissertations and get hired as\nprofessors. At first they were neither powerful nor\nnumerous. But as more of their peers joined them and the\nprevious generation of professors started to retire, they\ngradually became both.The reason political correctness began in the humanities and\nsocial sciences was that these fields offered more scope for\nthe injection of politics. A 1960s radical who got a job as\na physics professor could still attend protests, but his\npolitical beliefs wouldn't affect his work. Whereas research\nin sociology and modern literature can be made as political\nas you like.\n[2]I saw political correctness arise. When I started college in\n1982 it was not yet a thing. Female students might object if\nsomeone said something they considered sexist, but no one\nwas getting reported for it. It was still not a thing when\nI started grad school in 1986. It was definitely a thing in\n1988 though, and by the early 1990s it seemed to pervade\ncampus life.What happened? How did protest become punishment? Why were\nthe late 1980s the point at which protests against male\nchauvinism (as it used to be called) morphed into formal\ncomplaints to university authorities about sexism?\nBasically, the 1960s radicals got tenure. They became the\nEstablishment they'd protested against two decades before.\nNow they were in a position not just to speak out about\ntheir ideas, but to enforce them.A new set of moral rules to enforce was exciting news to a\ncertain kind of student. What made it particularly exciting\nwas that they were allowed to attack professors. I remember\nnoticing that aspect of political correctness at the time.\nIt wasn't simply a grass-roots student movement. It was\nfaculty members encouraging students to attack other faculty\nmembers. In that respect it was like the Cultural\nRevolution. That wasn't a grass-roots movement either; that\nwas Mao unleashing the younger generation on his political\nopponents. And in fact when Roderick MacFarquhar started\nteaching a class on the Cultural Revolution at Harvard in\nthe late 1980s, many saw it as a comment on current events.\nI don't know if it actually was, but people thought it was,\nand that means the similarities were obvious.\n[3]College students larp. It's their nature. It's usually\nharmless. But larping morality turned out to be a poisonous\ncombination. The result was a kind of moral etiquette,\nsuperficial but very complicated. Imagine having to explain\nto a well-meaning visitor from another planet why using the\nphrase \"people of color\" is considered particularly\nenlightened, but saying \"colored people\" gets you fired. And\nwhy exactly one isn't supposed to use the word \"negro\" now,\neven though Martin Luther King used it constantly in his\nspeeches. There are no underlying principles. You'd just\nhave to give him a long list of rules to memorize.\n[4]\nThe danger of these rules was not just that they created\nland mines for the unwary, but that their elaborateness made\nthem an effective substitute for virtue. Whenever a society\nhas a concept of heresy and orthodoxy, orthodoxy becomes a\nsubstitute for virtue. You can be the worst person in the\nworld, but as long as you're orthodox you're better than\neveryone who isn't. This makes orthodoxy very attractive to\nbad people.But for it to work as a substitute for virtue, orthodoxy\nmust be difficult. If all you have to do to be orthodox is\nwear some garment or avoid saying some word, everyone knows\nto do it, and the only way to seem more virtuous than other\npeople is to actually be virtuous. The shallow, complicated,\nand frequently changing rules of political correctness made\nit the perfect substitute for actual virtue. And the result\nwas a world in which good people who weren't up to date on\ncurrent moral fashions were brought down by people whose\ncharacters would make you recoil in horror if you could see\nthem.One big contributing factor in the rise of political\ncorrectness was the lack of other things to be morally pure\nabout. Previous generations of prigs had been prigs mostly\nabout religion and sex. But among the cultural elite these\nwere the deadest of dead letters by the 1980s; if you were\nreligious, or a virgin, this was something you tended to\nconceal rather than advertise. So the sort of people who\nenjoy being moral enforcers had become starved of things to\nenforce. A new set of rules was just what they'd been\nwaiting for.Curiously enough, the tolerant side of the 1960s left helped\ncreate the conditions in which the intolerant side\nprevailed. The relaxed social rules advocated by the old,\neasy-going hippy left became the dominant ones, at least\namong the elite, and this left nothing for the naturally\nintolerant to be intolerant about.Another possibly contributing factor was the fall of the\nSoviet empire. Marxism had been a popular focus of moral\npurity on the left before political correctness emerged as a\ncompetitor, but the pro-democracy movements in Eastern Bloc\ncountries took most of the shine off it. Especially the fall\nof the Berlin Wall in 1989. You couldn't be on the side of\nthe Stasi. I remember looking at the moribund Soviet Studies\nsection of a used bookshop in Cambridge in the late 1980s\nand thinking \"what will those people go on about now?\" As it\nturned out the answer was right under my nose.One thing I noticed at the time about the first phase of\npolitical correctness was that it was more popular with\nwomen than men. As many writers (perhaps most eloquently\nGeorge Orwell) have observed, women seem more attracted than\nmen to the idea of being moral enforcers. But there was\nanother more specific reason women tended to be the\nenforcers of political correctness. There was at this time a\ngreat backlash against sexual harassment; the mid 1980s were\nthe point when the definition of sexual harassment was\nexpanded from explicit sexual advances to creating a\n\"hostile environment.\" Within universities the classic form\nof accusation was for a (female) student to say that a\nprofessor made her \"feel uncomfortable.\" But the vagueness\nof this accusation allowed the radius of forbidden behavior\nto expand to include talking about heterodox ideas. Those\nmake people uncomfortable too.\n[5]Was it sexist to propose that Darwin's greater male\nvariability hypothesis might explain some variation in human\nperformance? Sexist enough to get Larry Summers pushed out\nas president of Harvard, apparently. One woman who heard the\ntalk in which he mentioned this idea said it made her feel\n\"physically ill\" and that she had to leave halfway through.\nIf the test of a hostile environment is how it makes people\nfeel, this certainly sounds like one. And yet it does seem\nplausible that greater male variability explains some of the\nvariation in human performance. So which should prevail,\ncomfort or truth? Surely if truth should prevail anywhere,\nit should be in universities; that's supposed to be their\nspecialty; but for decades starting in the late 1980s the\npolitically correct tried to pretend this conflict didn't\nexist.\n[6]Political correctness seemed to burn out in the second half\nof the 1990s. One reason, perhaps the main reason, was that\nit literally became a joke. It offered rich material for\ncomedians, who performed their usual disinfectant action\nupon it. Humor is one of the most powerful weapons against\npriggishness of any sort, because prigs, being humorless,\ncan't respond in kind. Humor was what defeated Victorian\nprudishness, and by 2000 it seemed to have done the same\nthing to political correctness.Unfortunately this was an illusion. Within universities the\nembers of political correctness were still glowing brightly.\nAfter all, the forces that created it were still there. The\nprofessors who started it were now becoming deans and\ndepartment heads. And in addition to their departments there\nwere now a bunch of new ones explicitly focused on social\njustice. Students were still hungry for things to be morally\npure about. And there had been an explosion in the number of\nuniversity administrators, many of whose jobs involved\nenforcing various forms of political correctness.In the early 2010s the embers of political correctness burst\ninto flame anew. There were several differences between this\nnew phase and the original one. It was more virulent. It\nspread further into the real world, although it still burned\nhottest within universities. And it was concerned with a\nwider variety of sins. In the first phase of political\ncorrectness there were really only three things people got\naccused of: sexism, racism, and homophobia (which at the\ntime was a neologism invented for the purpose). But between\nthen and 2010 a lot of people had spent a lot of time trying\nto invent new kinds of -isms and -phobias and seeing which\ncould be made to stick.The second phase was, in multiple senses, political\ncorrectness metastasized. Why did it happen when it did? My\nguess is that it was due to the rise of social media,\nparticularly Tumblr and Twitter, because one of the most\ndistinctive features of the second wave of political\ncorrectness was the cancel mob: a mob of angry people\nuniting on social media to get someone ostracized or fired.\nIndeed this second wave of political correctness was\noriginally called \"cancel culture\"; it didn't start to be\ncalled \"wokeness\" till the 2020s.One aspect of social media that surprised almost everyone at\nfirst was the popularity of outrage. Users seemed to like\nbeing outraged. We're so used to this idea now that we take\nit for granted, but really it's pretty strange. Being\noutraged is not a pleasant feeling. You wouldn't expect\npeople to seek it out. But they do. And above all, they want\nto share it. I happened to be running a forum from 2007 to\n2014, so I can actually quantify how much they want to share\nit: our users were about three times more likely to upvote\nsomething if it outraged them.This tilt toward outrage wasn't due to wokeness. It's an\ninherent feature of social media, or at least this\ngeneration of it. But it did make social media the perfect\nmechanism for fanning the flames of wokeness.\n[7]It wasn't just public social networks that drove the rise of\nwokeness though. Group chat apps were also critical,\nespecially in the final step, cancellation. Imagine if a\ngroup of employees trying to get someone fired had to do it\nusing only email. It would be hard to organize a mob. But\nonce you have group chat, mobs form naturally.Another contributing factor in this second wave of political\ncorrectness was the dramatic increase in the polarization of\nthe press. In the print era, newspapers were constrained to\nbe, or at least seem, politically neutral. The department\nstores that ran ads in the New York Times wanted to reach\neveryone in the region, both liberal and conservative, so\nthe Times had to serve both. But the Times didn't regard\nthis neutrality as something forced upon them. They embraced\nit as their duty as a paper of record — as one of the big\nnewspapers that aimed to be chronicles of their times,\nreporting every sufficiently important story from a neutral\npoint of view.When I grew up the papers of record seemed timeless, almost\nsacred institutions. Papers like the New York Times and\nWashington Post had immense prestige, partly because other\nsources of news were limited, but also because they did make\nsome effort to be neutral.Unfortunately it turned out that the paper of record was\nmostly an artifact of the constraints imposed by print.\n[8]\nWhen your market was determined by geography, you had\nto be neutral. But publishing online enabled — in fact\nprobably forced — newspapers to switch to serving markets\ndefined by ideology instead of geography. Most that remained\nin business fell in the direction they'd already been\nleaning: left. On October 11, 2020 the New York Times\nannounced that \"The paper is in the midst of an evolution\nfrom the stodgy paper of record into a juicy collection of\ngreat narratives.\"\n[9]\nMeanwhile journalists, of a sort,\nhad arisen to serve the right as well. And so journalism,\nwhich in the previous era had been one of the great\ncentralizing forces, now became one of the great polarizing\nones.The rise of social media and the increasing polarization of\njournalism reinforced one another. In fact there arose a new\nvariety of journalism involving a loop through social media.\nSomeone would say something controversial on social media.\nWithin hours it would become a news story. Outraged readers\nwould then post links to the story on social media, driving\nfurther arguments online. It was the cheapest source of\nclicks imaginable. You didn't have to maintain overseas news\nbureaus or pay for month-long investigations. All you had to\ndo was watch Twitter for controversial remarks and repost\nthem on your site, with some additional comments to inflame\nreaders further.For the press there was money in wokeness. But they weren't\nthe only ones. That was one of the biggest differences\nbetween the two waves of political correctness: the first\nwas driven almost entirely by amateurs, but the second was\noften driven by professionals. For some it was their whole\njob. By 2010 a new class of administrators had arisen whose\njob was basically to enforce wokeness. They played a role\nsimilar to that of the political commissars who got attached\nto military and industrial organizations in the USSR: they\nweren't directly in the flow of the organization's work, but\nwatched from the side to ensure that nothing improper\nhappened in the doing of it. These new administrators could\noften be recognized by the word \"inclusion\" in their titles.\nWithin institutions this was the preferred euphemism for\nwokeness; a new list of banned words, for example, would\nusually be called an \"inclusive language guide.\"\n[10]This new class of bureaucrats pursued a woke agenda as if\ntheir jobs depended on it, because they did. If you hire\npeople to keep watch for a particular type of problem,\nthey're going to find it, because otherwise there's no\njustification for their existence.\n[11]\nBut these\nbureaucrats also represented a second and possibly even\ngreater danger. Many were involved in hiring, and when\npossible they tried to ensure their employers hired only\npeople who shared their political beliefs. The most\negregious cases were the new \"DEI statements\" that some\nuniversities started to require from faculty candidates,\nproving their commitment to wokeness. Some universities used\nthese statements as the initial filter and only even\nconsidered candidates who scored high enough on them. You're\nnot hiring Einstein that way; imagine what you get instead.Another factor in the rise of wokeness was the Black Lives\nMatter movement, which started in 2013 when a white man was\nacquitted after killing a black teenager in Florida. But\nthis didn't launch wokeness; it was well underway by 2013.Similarly for the Me Too Movement, which took off in 2017\nafter the first news stories about Harvey Weinstein's\nhistory of raping women. It accelerated wokeness, but didn't\nplay the same role in launching it that the 80s version did\nin launching political correctness.The election of Donald Trump in 2016 also accelerated\nwokeness, particularly in the press, where outrage now meant\ntraffic. Trump made the New York Times a lot of money:\nheadlines during his first administration mentioned his name\nat about four times the rate of previous presidents.In 2020 we saw the biggest accelerant of all, after a white\npolice officer asphyxiated a black suspect on video. At this\npoint the metaphorical fire became a literal one, as violent\nprotests broke out across America. But in retrospect this\nturned out to be peak woke, or close to it. By every measure\nI've seen, wokeness peaked in 2020 or 2021.Wokeness is sometimes described as a mind-virus. What makes\nit viral is that it defines new types of impropriety. Most\npeople are afraid of impropriety; they're never exactly sure\nwhat the social rules are or which ones they might be\nbreaking. Especially if the rules change rapidly. And since\nmost people already worry that they might be breaking rules\nthey don't know about, if you tell them they're breaking a\nrule, their default reaction is to believe you. Especially\nif multiple people tell them. Which in turn is a recipe for\nexponential growth. Zealots invent some new impropriety to\navoid. The first people to adopt it are fellow zealots,\neager for new ways to signal their virtue. If there are\nenough of these, the initial group of zealots is followed by\na much larger group, motivated by fear. They're not trying\nto signal virtue; they're just trying to avoid getting in\ntrouble. At this point the new impropriety is now firmly\nestablished. Plus its success has increased the rate of\nchange in social rules, which, remember, is one of the\nreasons people are nervous about which rules they might be\nbreaking. So the cycle accelerates.\n[12]What's true of individuals is even more true of\norganizations. Especially organizations without a powerful\nleader. Such organizations do everything based on \"best\npractices.\" There's no higher authority; if some new \"best\npractice\" achieves critical mass, they must adopt it. And\nin this case the organization can't do what it usually does\nwhen it's uncertain: delay. It might be committing\nimproprieties right now! So it's surprisingly easy for a\nsmall group of zealots to capture this type of organization\nby describing new improprieties it might be guilty of. \n[13]How does this kind of cycle ever end? Eventually it leads to\ndisaster, and people start to say enough is enough. The\nexcesses of 2020 made a lot of people say that.Since then wokeness has been in gradual but continual\nretreat. Corporate CEOs, starting with Brian Armstrong, have\nopenly rejected it. Universities, led by the University of\nChicago and MIT, have explicitly confirmed their commitment\nto free speech. Twitter, which was arguably the hub of\nwokeness, was bought by Elon Musk in order to neutralize it,\nand he seems to have succeeded — and not, incidentally, by\ncensoring left-wing users the way Twitter used to censor\nright-wing ones, but without censoring either.\n[14]\nConsumers have emphatically rejected brands that ventured\ntoo far into wokeness. The Bud Light brand may have been\npermanently damaged by it. I'm not going to claim Trump's\nsecond victory in 2024 was a referendum on wokeness; I think\nhe won, as presidential candidates always do, because he was\nmore charismatic; but voters' \ndisgust with wokeness must have helped.So what do we do now? Wokeness is already in retreat.\nObviously we should help it along. What's the best way to do\nthat? And more importantly, how do we avoid a third\noutbreak? After all, it seemed to be dead once, but came\nback worse than ever.In fact there's an even more ambitious goal: is there a way\nto prevent any similar outbreak of aggressively performative\nmoralism in the future — not just a third outbreak of\npolitical correctness, but the next thing like it? Because\nthere will be a next thing. Prigs are prigs by nature. They\nneed rules to obey and enforce, and now that Darwin has cut\noff their traditional supply of rules, they're constantly\nhungry for new ones. All they need is someone to meet them\nhalfway by defining a new way to be morally pure, and we'll\nsee the same phenomenon again.Let's start with the easier problem. Is there a simple,\nprincipled way to deal with wokeness? I think there is: to\nuse the customs we already have for dealing with religion.\nWokeness is effectively a religion, just with God replaced\nby protected classes. It's not even the first religion of\nthis kind; Marxism had a similar form, with God replaced by\nthe masses.\n[15]\nAnd we already have well-established\ncustoms for dealing with religion within organizations. You\ncan express your own religious identity and explain your\nbeliefs, but you can't call your coworkers infidels if they\ndisagree, or try to ban them from saying things that\ncontradict its doctrines, or insist that the organization\nadopt yours as its official religion.If we're not sure what to do about any particular\nmanifestation of wokeness, imagine we were dealing with some\nother religion, like Christianity. Should we have people\nwithin organizations whose jobs are to enforce woke\northodoxy? No, because we wouldn't have people whose jobs\nwere to enforce Christian orthodoxy. Should we censor\nwriters or \nscientists whose work contradicts woke doctrines?\nNo, because we wouldn't do this to people whose work\ncontradicted Christian teachings. Should job candidates be\nrequired to write DEI statements? Of course not; imagine an\nemployer requiring proof of one's religious beliefs. Should\nstudents and employees have to participate in woke\nindoctrination sessions in which they're required to answer\nquestions about their beliefs to ensure compliance? No,\nbecause we wouldn't dream of catechizing people in this way\nabout their religion.\n[16]One shouldn't feel bad about not wanting to watch woke\nmovies any more than one would feel bad about not wanting to\nlisten to Christian rock. In my twenties I drove across\nAmerica several times, listening to local radio stations.\nOccasionally I'd turn the dial and hear some new song. But\nthe moment anyone mentioned Jesus I'd turn the dial again.\nEven the tiniest bit of being preached to was enough to make\nme lose interest.But by the same token we should not automatically reject\neverything the woke believe. I'm not a Christian, but I can\nsee that many Christian principles are good ones. It would\nbe a mistake to discard them all just because one didn't\nshare the religion that espoused them. It would be the sort\nof thing a religious zealot would do.If we have genuine pluralism, I think we'll be safe from\nfuture outbreaks of woke intolerance. Wokeness itself won't\ngo away. There will for the foreseeable future continue to\nbe pockets of woke zealots inventing new moral fashions. The\nkey is not to let them treat their fashions as normative.\nThey can change what their coreligionists are allowed to say\nevery few months if they like, but they mustn't be allowed\nto change what we're allowed to say.\n[17]The more general problem — how to prevent similar outbreaks\nof aggressively performative moralism — is of course\nharder. Here we're up against human nature. There will\nalways be prigs. And in particular there will always be the\nenforcers among them, the \naggressively conventional-minded.\nThese people are born that way. Every society has them. So\nthe best we can do is to keep them bottled up.The aggressively conventional-minded aren't always on the\nrampage. Usually they just enforce whatever random rules are\nnearest to hand. They only become dangerous when some new\nideology gets a lot of them pointed in the same direction at\nonce. That's what happened during the Cultural Revolution,\nand to a lesser extent (thank God) in the two waves of\npolitical correctness we've experienced.We can't get rid of the aggressively conventional-minded.\n[18]\nAnd we couldn't prevent people from creating new\nideologies that appealed to them even if we wanted to. So if\nwe want to keep them bottled up, we have to do it one step\ndownstream. Fortunately when the aggressively\nconventional-minded go on the rampage they always do one\nthing that gives them away: they define new heresies to\npunish people for. So the best way to protect ourselves from\nfuture outbreaks of things like wokeness is to have powerful\nantibodies against the concept of heresy.We should have a conscious bias against defining new forms\nof heresy. Whenever anyone tries to ban saying something\nthat we'd previously been able to say, our initial\nassumption should be that they're wrong. Only our initial\nassumption of course. If they can prove we should stop\nsaying it, then we should. But the burden of proof is on\nthem. In liberal democracies, people trying to prevent\nsomething from being said will usually claim they're not\nmerely engaging in censorship, but trying to prevent some\nform of \"harm\". And maybe they're right. But once again, the\nburden of proof is on them. It's not enough to claim harm;\nthey have to prove it.As long as the aggressively conventional-minded continue to\ngive themselves away by banning heresies, we'll always be\nable to notice when they become aligned behind some new\nideology. And if we always fight back at that point, with\nany luck we can stop them in their tracks.The number of true things we can't say\nshould not increase. If it does, something is wrong.Notes[0]\nThis was not the original meaning of \"woke,\" but it's rarely\nused in the original sense now. Now the pejorative sense is\nthe dominant one.[1]\nWhy did 1960s radicals focus on the causes they did?\nOne of the people who reviewed drafts of this essay\nexplained this so well that I asked if I could quote him:\n\n  The middle-class student protestors of the New Left\n  rejected the socialist/Marxist left as unhip. They were\n  interested in sexier forms of oppression uncovered by\n  cultural analysis (Marcuse) and abstruse \"Theory\". Labor\n  politics became stodgy and old-fashioned. This took a\n  couple generations to work through. The woke ideology's\n  conspicuous lack of interest in the working class is the\n  tell-tale sign. Such fragments as are, er, left of the old\n  left are anti-woke, and meanwhile the actual working class\n  shifted to the populist right and gave us Trump. Trump and\n  wokeness are cousins.The middle-class origins of wokeness smoothed its way\n  through the institutions because it had no interest in\n  \"seizing the means of production\" (how quaint such phrases\n  seem now), which would quickly have run up against hard\n  state and corporate power. The fact that wokeness only\n  expressed interest in other kinds of class (race, sex,\n  etc) signalled compromise with existing power: give us\n  power within your system and we'll bestow the resource we\n  control — moral rectitude — upon you. As an ideological\n  stalking horse for gaining control over discourse and\n  institutions, this succeeded where a more ambitious\n  revolutionary program would not have.\n\n[2]\nIt helped that the humanities and social sciences also\nincluded some of the biggest and easiest undergrad majors.\nIf a political movement had to start with physics students,\nit could never get off the ground; there would be too few of\nthem, and they wouldn't have the time to spare.At the top universities these majors are not as big as they\nused to be, though. A \n2022 survey found that only 7% of\nHarvard undergrads plan to major in the humanities, vs\nnearly 30% during the 1970s. I expect wokeness is at least\npart of the reason; when undergrads consider majoring in\nEnglish, it's presumably because they love the written word\nand not because they want to listen to lectures about\nracism.[3]\nThe puppet-master-and-puppet character of political\ncorrectness became clearly visible when a bakery near\nOberlin College was falsely accused of race discrimination\nin 2016. In the subsequent civil trial, lawyers for the\nbakery produced a text message from Oberlin Dean of Students\nMeredith Raimondo that read \"I'd say unleash the students if\nI wasn't convinced this needs to be put behind us.\"[4]\nThe woke sometimes claim that wokeness is simply\ntreating people with respect. But if it were, that would be\nthe only rule you'd have to remember, and this is comically\nfar from being the case. My younger son likes to imitate\nvoices, and at one point when he was about seven I had to\nexplain which accents it was currently safe to imitate\npublicly and which not. It took about ten minutes, and I\nstill hadn't covered all the cases.[5]\nIn 1986 the Supreme Court ruled that creating a\nhostile work environment could constitute sex\ndiscrimination, which in turn affected universities via\nTitle IX. The court specified that the test of a hostile\nenvironment was whether it would bother a reasonable person,\nbut since for a professor merely being the subject of a\nsexual harassment complaint would be a disaster whether the\ncomplainant was reasonable or not, in practice any joke or\nremark remotely connected with sex was now effectively\nforbidden. Which meant we'd now come full circle to\nVictorian codes of behavior, when there was a large class of\nthings that might not be said \"with ladies present.\"[6]\nMuch as they tried to pretend there was no conflict\nbetween diversity and quality. But you can't simultaneously\noptimize for two things that aren't identical. What\ndiversity actually means, judging from the way the term is\nused, is proportional representation, and unless you're\nselecting a group whose purpose is to be representative,\nlike poll respondents, optimizing for proportional\nrepresentation has to come at the expense of quality. This\nis not because of anything about representation; it's the\nnature of optimization; optimizing for x has to come at the\nexpense of y unless x and y are identical.[7]\nMaybe societies will eventually develop antibodies to\nviral outrage. Maybe we were just the first to be exposed to\nit, so it tore through us like an epidemic through a\npreviously isolated population. I'm fairly confident that it\nwould be possible to create new social media apps that were\nless driven by outrage, and an app of this type would have a\ngood chance of stealing users from existing ones, because\nthe smartest people would tend to migrate to it.[8]\nI say \"mostly\" because I have hopes that journalistic\nneutrality will return in some form. There is some market\nfor unbiased news, and while it may be small, it's valuable.\nThe rich and powerful want to know what's really going on;\nthat's how they became rich and powerful.[9]\nThe Times made this momentous announcement very\ninformally, in passing in the middle of an \narticle about a\nTimes reporter who'd been criticized for inaccuracy. It's\nquite possible no senior editor even approved it. But it's\nsomehow appropriate that this particular universe ended with\na whimper rather than a bang.[10]\nAs the acronym DEI goes out of fashion, many of these\nbureaucrats will try to go underground by changing their\ntitles. It looks like \"belonging\" will be a popular option.[11]\nIf you've ever wondered why our legal system includes\nprotections like the separation of prosecutor, judge, and\njury, the right to examine evidence and cross-examine\nwitnesses, and the right to be represented by legal counsel,\nthe de facto \nparallel legal system\nestablished by Title IX\nmakes that all too clear.[12]\nThe invention of new improprieties is most visible in\nthe rapid evolution of woke nomenclature. This is\nparticularly annoying to me as a writer, because the new\nnames are always worse. Any religious observance has to be\ninconvenient and slightly absurd; otherwise gentiles would\ndo it too. So \"slaves\" becomes \"enslaved individuals.\" But\nweb search can show us the leading edge of moral growth in\nreal time: if you search for \"individuals experiencing\nslavery\" you will as of this writing find five legit\nattempts to use the phrase, and you'll even find two for\n\"individuals experiencing enslavement.\"[13]\nOrganizations that do dubious things are particularly\nconcerned with propriety, which is how you end up with\nabsurdities like tobacco and oil companies having higher ESG\nratings than Tesla.[14]\nElon did something else that tilted Twitter rightward\nthough: he gave more visibility to paying users. Paying\nusers lean right on average, because people on the far left\ndislike Elon and don't want to give him money. Elon\npresumably knew this would happen. On the other hand, the\npeople on the far left have only themselves to blame; they\ncould tilt Twitter back to the left tomorrow if they wanted\nto.[15]\nIt even, as James Lindsay and Peter Boghossian\npointed out, has a concept of original sin: privilege. Which\nmeans unlike Christianity's egalitarian version, people have varying\ndegrees of it. An able-bodied straight white\nAmerican male is born with such a load of sin that only by\nthe most abject repentance can he be saved.Wokeness also shares something rather funny with many actual\nversions of Christianity: like God, the people for whose\nsake wokeness purports to act are often revolted by the\nthings done in their name.[16]\nThere is one exception to most of these rules: actual\nreligious organizations. It's reasonable for them to insist\non orthodoxy. But they in turn should declare that they're\nreligious organizations. It's rightly considered shady\nwhen something that appears to be an ordinary business or\npublication turns out to be a religious organization.[17]\nI don't want to give the impression that it will be\nsimple to roll back wokeness. There will be places where the\nfight inevitably gets messy — particularly within\nuniversities, which everyone has to share, yet which are\ncurrently the most pervaded by wokeness of any institutions.[18]\nYou can however get rid of aggressively\nconventional-minded people within an organization, and in\nmany if not most organizations this would be an excellent\nidea. Even a handful of them can do a lot of damage. I bet\nyou'd feel a noticeable improvement going from a handful to\nnone.Thanks to Sam Altman, \nBen Miller, Daniel Gackle, Robin Hanson, Jessica\nLivingston, Greg Lukianoff, Harj Taggar, Garry Tan, and Tim\nUrban for reading drafts of this."
        ],
        "source_file": null
    }
]